{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE4WC2_4wygJ"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
        "\n",
        "\n",
        "\n",
        "**Keywords**: Sexism Detection, Multi-class Classification, RNNs, Transformers, Huggingface\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL69zGpmx01k"
      },
      "source": [
        "# Contact\n",
        "\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "\n",
        "\n",
        "- Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "\n",
        "- Eleonora Mancini -> e.mancini@unibo.it\n",
        "\n",
        "\n",
        "\n",
        "Professor:\n",
        "\n",
        "- Paolo Torroni -> p.torroni@unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55jnW-xKxi-2"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "You are asked to address the [EXIST 2023 Task 1](https://clef2023.clef-initiative.eu/index.php?page=Pages/labs.html#EXIST) on sexism detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HWp5bGwySsb"
      },
      "source": [
        "## Problem Definition\n",
        "\n",
        "The systems have to decide whether or not a given tweet contains or describes sexist expressions or behaviors (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behavior).\n",
        "\n",
        "\n",
        "\n",
        "### Examples:\n",
        "\n",
        "\n",
        "\n",
        "**Text**: *Can’t go a day without women womening*\n",
        "\n",
        "\n",
        "\n",
        "**Label**: Sexist\n",
        "\n",
        "\n",
        "\n",
        "**Text**: *''Society's set norms! Happy men's day though!#weareequal''*\n",
        "\n",
        "\n",
        "\n",
        "**Label**: Not sexist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-11-27T16:22:28.580188Z",
          "iopub.status.busy": "2024-11-27T16:22:28.579935Z",
          "iopub.status.idle": "2024-11-27T16:22:45.103942Z",
          "shell.execute_reply": "2024-11-27T16:22:45.103095Z",
          "shell.execute_reply.started": "2024-11-27T16:22:28.580162Z"
        },
        "id": "brt-0TQat-uX",
        "outputId": "da3c0191-50d0-4f61-cb73-6c4cf2de3870",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "--2025-01-05 12:06:17--  https://raw.githubusercontent.com/nlp-unibo/nlp-course-material/72c93981fe38020285a16e1558d5d4a314bb1b82/2024-2025/Assignment%201/data/test.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 492435 (481K) [text/plain]\n",
            "Saving to: ‘data/test.json’\n",
            "\n",
            "data/test.json      100%[===================>] 480.89K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-01-05 12:06:17 (23.1 MB/s) - ‘data/test.json’ saved [492435/492435]\n",
            "\n",
            "--2025-01-05 12:06:17--  https://raw.githubusercontent.com/nlp-unibo/nlp-course-material/72c93981fe38020285a16e1558d5d4a314bb1b82/2024-2025/Assignment%201/data/training.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6217980 (5.9M) [text/plain]\n",
            "Saving to: ‘data/training.json’\n",
            "\n",
            "data/training.json  100%[===================>]   5.93M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-01-05 12:06:18 (155 MB/s) - ‘data/training.json’ saved [6217980/6217980]\n",
            "\n",
            "--2025-01-05 12:06:18--  https://raw.githubusercontent.com/nlp-unibo/nlp-course-material/72c93981fe38020285a16e1558d5d4a314bb1b82/2024-2025/Assignment%201/data/validation.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1159313 (1.1M) [text/plain]\n",
            "Saving to: ‘data/validation.json’\n",
            "\n",
            "data/validation.jso 100%[===================>]   1.11M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-01-05 12:06:18 (44.8 MB/s) - ‘data/validation.json’ saved [1159313/1159313]\n",
            "\n",
            "--2025-01-05 12:06:18--  https://zenodo.org/record/3234051/files/embeddings-m-model.vec?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.48.194, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/3234051/files/embeddings-m-model.vec [following]\n",
            "--2025-01-05 12:06:19--  https://zenodo.org/records/3234051/files/embeddings-m-model.vec\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1146794415 (1.1G) [application/octet-stream]\n",
            "Saving to: ‘spanish_embed.vec’\n",
            "\n",
            "spanish_embed.vec   100%[===================>]   1.07G  81.3MB/s    in 14s     \n",
            "\n",
            "2025-01-05 12:06:33 (77.8 MB/s) - ‘spanish_embed.vec’ saved [1146794415/1146794415]\n",
            "\n",
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate\n",
        "!mkdir -p ./data\n",
        "!wget https://raw.githubusercontent.com/nlp-unibo/nlp-course-material/72c93981fe38020285a16e1558d5d4a314bb1b82/2024-2025/Assignment%201/data/test.json -O data/test.json\n",
        "!wget https://raw.githubusercontent.com/nlp-unibo/nlp-course-material/72c93981fe38020285a16e1558d5d4a314bb1b82/2024-2025/Assignment%201/data/training.json -O data/training.json\n",
        "!wget https://raw.githubusercontent.com/nlp-unibo/nlp-course-material/72c93981fe38020285a16e1558d5d4a314bb1b82/2024-2025/Assignment%201/data/validation.json -O data/validation.json\n",
        "!wget https://zenodo.org/record/3234051/files/embeddings-m-model.vec?download=1 -O spanish_embed.vec\n",
        "!python -m spacy download es_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T16:23:23.651686Z",
          "iopub.status.busy": "2024-11-27T16:23:23.651030Z",
          "iopub.status.idle": "2024-11-27T16:24:02.076157Z",
          "shell.execute_reply": "2024-11-27T16:24:02.075503Z",
          "shell.execute_reply.started": "2024-11-27T16:23:23.651645Z"
        },
        "id": "c-wwUVa7IMDm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "import gensim.downloader as gloader\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import nltk\n",
        "import keras\n",
        "import evaluate\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import Dataset\n",
        "#from functools import reduce\n",
        "from keras import Input\n",
        "from keras.layers import Bidirectional, LSTM, Dense, Embedding\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras.optimizers import Nadam\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag, OrderedDict\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet, stopwords\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_recall_curve, ConfusionMatrixDisplay, PrecisionRecallDisplay\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, AutoTokenizer, DataCollatorWithPadding, Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6q1svotscl1"
      },
      "source": [
        "#### Set an initial seed for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:02.078124Z",
          "iopub.status.busy": "2024-11-27T16:24:02.077599Z",
          "iopub.status.idle": "2024-11-27T16:24:02.081859Z",
          "shell.execute_reply": "2024-11-27T16:24:02.081061Z",
          "shell.execute_reply.started": "2024-11-27T16:24:02.078097Z"
        },
        "id": "EgWyKKLe--FT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iu1X4I98M8B"
      },
      "source": [
        "# [Task 1 - 1.0 points] Corpus\n",
        "\n",
        "\n",
        "\n",
        "We have preparared a small version of EXIST dataset in our dedicated [Github repository](https://github.com/lt-nlp-lab-unibo/nlp-course-material/tree/main/2024-2025/Assignment%201/data).\n",
        "\n",
        "\n",
        "\n",
        "Check the `A1/data` folder. It contains 3 `.json` files representing `training`, `validation` and `test` sets.\n",
        "\n",
        "\n",
        "\n",
        "The three sets are slightly unbalanced, with a bias toward the `Non-sexist` class.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AASoMV9XN5l6"
      },
      "source": [
        "### Dataset Description\n",
        "\n",
        "- The dataset contains tweets in both English and Spanish.\n",
        "\n",
        "- There are labels for multiple tasks, but we are focusing on **Task 1**.\n",
        "\n",
        "- For Task 1, soft labels are assigned by six annotators.\n",
        "\n",
        "- The labels for Task 1 represent whether the tweet is sexist (\"YES\") or not (\"NO\").\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFjwB_lCOQKj"
      },
      "source": [
        "\n",
        "\n",
        "### Example\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \"203260\": {\n",
        "\n",
        "        \"id_EXIST\": \"203260\",\n",
        "\n",
        "        \"lang\": \"en\",\n",
        "\n",
        "        \"tweet\": \"ik when mandy says “you look like a whore” i look cute as FUCK\",\n",
        "\n",
        "        \"number_annotators\": 6,\n",
        "\n",
        "        \"annotators\": [\"Annotator_473\", \"Annotator_474\", \"Annotator_475\", \"Annotator_476\", \"Annotator_477\", \"Annotator_27\"],\n",
        "\n",
        "        \"gender_annotators\": [\"F\", \"F\", \"M\", \"M\", \"M\", \"F\"],\n",
        "\n",
        "        \"age_annotators\": [\"18-22\", \"23-45\", \"18-22\", \"23-45\", \"46+\", \"46+\"],\n",
        "\n",
        "        \"labels_task1\": [\"YES\", \"YES\", \"YES\", \"NO\", \"YES\", \"YES\"],\n",
        "\n",
        "        \"labels_task2\": [\"DIRECT\", \"DIRECT\", \"REPORTED\", \"-\", \"JUDGEMENTAL\", \"REPORTED\"],\n",
        "\n",
        "        \"labels_task3\": [\n",
        "\n",
        "          [\"STEREOTYPING-DOMINANCE\"],\n",
        "\n",
        "          [\"OBJECTIFICATION\"],\n",
        "\n",
        "          [\"SEXUAL-VIOLENCE\"],\n",
        "\n",
        "          [\"-\"],\n",
        "\n",
        "          [\"STEREOTYPING-DOMINANCE\", \"OBJECTIFICATION\"],\n",
        "\n",
        "          [\"OBJECTIFICATION\"]\n",
        "\n",
        "        ],\n",
        "\n",
        "        \"split\": \"TRAIN_EN\"\n",
        "\n",
        "      }\n",
        "\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ45bvuOOJ7I"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "1. **Download** the `A1/data` folder.\n",
        "\n",
        "2. **Load** the three JSON files and encode them as pandas dataframes.\n",
        "\n",
        "3. **Generate hard labels** for Task 1 using majority voting and store them in a new dataframe column called `hard_label_task1`. Items without a clear majority will be removed from the dataset.\n",
        "\n",
        "4. **Filter the DataFrame** to keep only rows where the `lang` column is `'en'`.\n",
        "\n",
        "5. **Remove unwanted columns**: Keep only `id_EXIST`, `lang`, `tweet`, and `hard_label_task1`.\n",
        "\n",
        "6. **Encode the `hard_label_task1` column**: Use 1 to represent \"YES\" and 0 to represent \"NO\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hFVl4cFIMDt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-2E-GAyIMDu"
      },
      "source": [
        "1. **Download** the `A1/data` folder.\n",
        "\n",
        "2. **Load** the three JSON files and encode them as pandas dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:02.083008Z",
          "iopub.status.busy": "2024-11-27T16:24:02.082782Z",
          "iopub.status.idle": "2024-11-27T16:24:03.829638Z",
          "shell.execute_reply": "2024-11-27T16:24:03.828711Z",
          "shell.execute_reply.started": "2024-11-27T16:24:02.082986Z"
        },
        "id": "C2bPnLnfIMDv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_json(\"./data/training.json\").transpose().set_index(\"id_EXIST\")\n",
        "df_test = pd.read_json(\"./data/test.json\").transpose().set_index(\"id_EXIST\")\n",
        "df_val = pd.read_json(\"./data/validation.json\").transpose().set_index(\"id_EXIST\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:03.831637Z",
          "iopub.status.busy": "2024-11-27T16:24:03.831326Z",
          "iopub.status.idle": "2024-11-27T16:24:03.862157Z",
          "shell.execute_reply": "2024-11-27T16:24:03.861433Z",
          "shell.execute_reply.started": "2024-11-27T16:24:03.831611Z"
        },
        "id": "7exPCi34IMDw",
        "outputId": "90104e8d-1bf2-443e-b28a-3e1370593526",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         lang                                              tweet  \\\n",
              "id_EXIST                                                           \n",
              "100001     es  @TheChiflis Ignora al otro, es un capullo.El p...   \n",
              "100002     es  @ultimonomada_ Si comicsgate se parece en algo...   \n",
              "100003     es  @Steven2897 Lee sobre Gamergate, y como eso ha...   \n",
              "100004     es  @Lunariita7 Un retraso social bastante lamenta...   \n",
              "100005     es  @novadragon21 @icep4ck @TvDannyZ Entonces como...   \n",
              "\n",
              "         number_annotators                                         annotators  \\\n",
              "id_EXIST                                                                        \n",
              "100001                   6  [Annotator_1, Annotator_2, Annotator_3, Annota...   \n",
              "100002                   6  [Annotator_7, Annotator_8, Annotator_9, Annota...   \n",
              "100003                   6  [Annotator_7, Annotator_8, Annotator_9, Annota...   \n",
              "100004                   6  [Annotator_13, Annotator_14, Annotator_15, Ann...   \n",
              "100005                   6  [Annotator_19, Annotator_20, Annotator_21, Ann...   \n",
              "\n",
              "           gender_annotators                          age_annotators  \\\n",
              "id_EXIST                                                               \n",
              "100001    [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
              "100002    [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
              "100003    [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
              "100004    [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
              "100005    [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
              "\n",
              "                           labels_task1  \\\n",
              "id_EXIST                                  \n",
              "100001    [YES, YES, NO, YES, YES, YES]   \n",
              "100002        [NO, NO, NO, NO, YES, NO]   \n",
              "100003         [NO, NO, NO, NO, NO, NO]   \n",
              "100004      [NO, NO, YES, NO, YES, YES]   \n",
              "100005     [YES, NO, YES, NO, YES, YES]   \n",
              "\n",
              "                                               labels_task2  \\\n",
              "id_EXIST                                                      \n",
              "100001    [REPORTED, JUDGEMENTAL, -, REPORTED, JUDGEMENT...   \n",
              "100002                              [-, -, -, -, DIRECT, -]   \n",
              "100003                                   [-, -, -, -, -, -]   \n",
              "100004                [-, -, DIRECT, -, REPORTED, REPORTED]   \n",
              "100005    [REPORTED, -, JUDGEMENTAL, -, JUDGEMENTAL, DIR...   \n",
              "\n",
              "                                               labels_task3     split  \n",
              "id_EXIST                                                               \n",
              "100001    [[OBJECTIFICATION], [OBJECTIFICATION, SEXUAL-V...  TRAIN_ES  \n",
              "100002         [[-], [-], [-], [-], [OBJECTIFICATION], [-]]  TRAIN_ES  \n",
              "100003                       [[-], [-], [-], [-], [-], [-]]  TRAIN_ES  \n",
              "100004    [[-], [-], [IDEOLOGICAL-INEQUALITY], [-], [IDE...  TRAIN_ES  \n",
              "100005    [[STEREOTYPING-DOMINANCE, OBJECTIFICATION], [-...  TRAIN_ES  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ae3c0e0-a232-43b1-b350-b7f5956af89b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lang</th>\n",
              "      <th>tweet</th>\n",
              "      <th>number_annotators</th>\n",
              "      <th>annotators</th>\n",
              "      <th>gender_annotators</th>\n",
              "      <th>age_annotators</th>\n",
              "      <th>labels_task1</th>\n",
              "      <th>labels_task2</th>\n",
              "      <th>labels_task3</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_EXIST</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100001</th>\n",
              "      <td>es</td>\n",
              "      <td>@TheChiflis Ignora al otro, es un capullo.El p...</td>\n",
              "      <td>6</td>\n",
              "      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n",
              "      <td>[F, F, F, M, M, M]</td>\n",
              "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
              "      <td>[YES, YES, NO, YES, YES, YES]</td>\n",
              "      <td>[REPORTED, JUDGEMENTAL, -, REPORTED, JUDGEMENT...</td>\n",
              "      <td>[[OBJECTIFICATION], [OBJECTIFICATION, SEXUAL-V...</td>\n",
              "      <td>TRAIN_ES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100002</th>\n",
              "      <td>es</td>\n",
              "      <td>@ultimonomada_ Si comicsgate se parece en algo...</td>\n",
              "      <td>6</td>\n",
              "      <td>[Annotator_7, Annotator_8, Annotator_9, Annota...</td>\n",
              "      <td>[F, F, F, M, M, M]</td>\n",
              "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
              "      <td>[NO, NO, NO, NO, YES, NO]</td>\n",
              "      <td>[-, -, -, -, DIRECT, -]</td>\n",
              "      <td>[[-], [-], [-], [-], [OBJECTIFICATION], [-]]</td>\n",
              "      <td>TRAIN_ES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100003</th>\n",
              "      <td>es</td>\n",
              "      <td>@Steven2897 Lee sobre Gamergate, y como eso ha...</td>\n",
              "      <td>6</td>\n",
              "      <td>[Annotator_7, Annotator_8, Annotator_9, Annota...</td>\n",
              "      <td>[F, F, F, M, M, M]</td>\n",
              "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
              "      <td>[NO, NO, NO, NO, NO, NO]</td>\n",
              "      <td>[-, -, -, -, -, -]</td>\n",
              "      <td>[[-], [-], [-], [-], [-], [-]]</td>\n",
              "      <td>TRAIN_ES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100004</th>\n",
              "      <td>es</td>\n",
              "      <td>@Lunariita7 Un retraso social bastante lamenta...</td>\n",
              "      <td>6</td>\n",
              "      <td>[Annotator_13, Annotator_14, Annotator_15, Ann...</td>\n",
              "      <td>[F, F, F, M, M, M]</td>\n",
              "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
              "      <td>[NO, NO, YES, NO, YES, YES]</td>\n",
              "      <td>[-, -, DIRECT, -, REPORTED, REPORTED]</td>\n",
              "      <td>[[-], [-], [IDEOLOGICAL-INEQUALITY], [-], [IDE...</td>\n",
              "      <td>TRAIN_ES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100005</th>\n",
              "      <td>es</td>\n",
              "      <td>@novadragon21 @icep4ck @TvDannyZ Entonces como...</td>\n",
              "      <td>6</td>\n",
              "      <td>[Annotator_19, Annotator_20, Annotator_21, Ann...</td>\n",
              "      <td>[F, F, F, M, M, M]</td>\n",
              "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
              "      <td>[YES, NO, YES, NO, YES, YES]</td>\n",
              "      <td>[REPORTED, -, JUDGEMENTAL, -, JUDGEMENTAL, DIR...</td>\n",
              "      <td>[[STEREOTYPING-DOMINANCE, OBJECTIFICATION], [-...</td>\n",
              "      <td>TRAIN_ES</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ae3c0e0-a232-43b1-b350-b7f5956af89b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ae3c0e0-a232-43b1-b350-b7f5956af89b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ae3c0e0-a232-43b1-b350-b7f5956af89b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c5e9436d-633e-4689-a4af-e61d7d4b6786\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c5e9436d-633e-4689-a4af-e61d7d4b6786')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c5e9436d-633e-4689-a4af-e61d7d4b6786 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 6920,\n  \"fields\": [\n    {\n      \"column\": \"id_EXIST\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6920,\n        \"samples\": [\n          \"100469\",\n          \"101957\",\n          \"100801\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"en\",\n          \"es\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6920,\n        \"samples\": [\n          \"@AnelPerezM Pues.... realmente sabes cu\\u00e1ndo alguien aumenta tu serotonina... porque ver una mujer atractiva pues si.... pero que realmente te enamore...lo sientes porque eso te pone realmente feliz.\",\n          \"@giuli_cc:A confesi\\u00f3n de parte relevo de prueba.Claramente el ex Minedu CUENCA sostiene q el enfoque de g\\u00e9nero es lo m\\u00e1s alejado a lo binario.\\u00bfNo q el enfoque de g\\u00e9nero era buscar la igualdad entre VAR\\u00d3N Y MUJER?Claramente el EdG es un sin fin de g\\u00e9neros que quieren ense\\u00f1ar. https://t.co/UIxAyyC5nR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number_annotators\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotators\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender_annotators\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age_annotators\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels_task1\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels_task2\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels_task3\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"TRAIN_EN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:03.918524Z",
          "iopub.status.busy": "2024-11-27T16:24:03.918222Z",
          "iopub.status.idle": "2024-11-27T16:24:03.923408Z",
          "shell.execute_reply": "2024-11-27T16:24:03.922466Z",
          "shell.execute_reply.started": "2024-11-27T16:24:03.918499Z"
        },
        "id": "g4XYc8xJIMDz",
        "outputId": "9e525d49-d844-4a33-ca3b-49477d3f3bf5",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Training dataset shape: (6920, 10)\n",
            "- Test dataset shape: (312, 10)\n",
            "- Validation dataset shape: (726, 10)\n"
          ]
        }
      ],
      "source": [
        "print(\"- Training dataset shape:\", df_train.shape)\n",
        "print(\"- Test dataset shape:\", df_test.shape)\n",
        "print(\"- Validation dataset shape:\", df_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b--7FrOoIMD1"
      },
      "source": [
        "3. **Generate hard labels** for Task 1 using majority voting and store them in a new dataframe column called `hard_label_task1`. Items without a clear majority will be removed from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:03.924597Z",
          "iopub.status.busy": "2024-11-27T16:24:03.924328Z",
          "iopub.status.idle": "2024-11-27T16:24:03.976411Z",
          "shell.execute_reply": "2024-11-27T16:24:03.975809Z",
          "shell.execute_reply.started": "2024-11-27T16:24:03.924574Z"
        },
        "id": "8lw8oBkuIMD1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_train_cp = df_train.copy()\n",
        "df_test_cp = df_test.copy()\n",
        "df_val_cp = df_val.copy()\n",
        "\n",
        "# For each row of the datasets, using df.apply(), this sets the values for the new \"hard_labels_task1\" column.\n",
        "\n",
        "df_train_cp['hard_labels_task1'] = df_train_cp['labels_task1'].apply(\n",
        "    lambda x: 'YES' if x.count('YES') > x.count('NO') else ('NO' if x.count('NO') > x.count('YES') else np.NAN)\n",
        ")\n",
        "\n",
        "df_test_cp['hard_labels_task1'] = df_test_cp['labels_task1'].apply(\n",
        "    lambda x: 'YES' if x.count('YES') > x.count('NO') else ('NO' if x.count('NO') > x.count('YES') else np.NAN)\n",
        ")\n",
        "\n",
        "df_val_cp['hard_labels_task1'] = df_val_cp['labels_task1'].apply(\n",
        "    lambda x: 'YES' if x.count('YES') > x.count('NO') else ('NO' if x.count('NO') > x.count('YES') else np.NAN)\n",
        ")\n",
        "\n",
        "\n",
        "# Since for those rows without a clear majority vote the \"hard_labels_task1\" column was set to \"NaN\",\n",
        "# this removes all those rows with the \"NaN\" value using df.dropna().\n",
        "\n",
        "df_train_cp.dropna(inplace=True)\n",
        "df_test_cp.dropna(inplace=True)\n",
        "df_val_cp.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yABrJFiBIMD2"
      },
      "source": [
        "4. **Filter the DataFrame** to keep only rows where the `lang` column is `'en'`.\n",
        "\n",
        "   **Expansion:** it has been decided to explore also spanish tweets, with the same preprocessing as the english text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:03.977421Z",
          "iopub.status.busy": "2024-11-27T16:24:03.977183Z",
          "iopub.status.idle": "2024-11-27T16:24:03.986064Z",
          "shell.execute_reply": "2024-11-27T16:24:03.985316Z",
          "shell.execute_reply.started": "2024-11-27T16:24:03.977391Z"
        },
        "id": "MuwMzWfoIMD3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# English tweets\n",
        "df_train_T1 = df_train_cp[df_train_cp[\"lang\"] == \"en\"]\n",
        "df_test_T1 = df_test_cp[df_test_cp[\"lang\"] == \"en\"]\n",
        "df_val_T1 = df_val_cp[df_val_cp[\"lang\"] == \"en\"]\n",
        "\n",
        "# Spanish tweets\n",
        "df_train_es = df_train_cp[df_train_cp[\"lang\"] == \"es\"]\n",
        "df_test_es = df_test_cp[df_test_cp[\"lang\"] == \"es\"]\n",
        "df_val_es = df_val_cp[df_val_cp[\"lang\"] == \"es\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2xc3PL5IMD3"
      },
      "source": [
        "5. **Remove unwanted columns**: Keep only `id_EXIST`, `lang`, `tweet`, and `hard_label_task1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:05.201191Z",
          "iopub.status.busy": "2024-11-27T16:24:05.200850Z",
          "iopub.status.idle": "2024-11-27T16:24:05.211590Z",
          "shell.execute_reply": "2024-11-27T16:24:05.210925Z",
          "shell.execute_reply.started": "2024-11-27T16:24:05.201160Z"
        },
        "id": "WjV5OjuwIMD3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# English tweets\n",
        "df_train_T1 = df_train_T1.drop(\n",
        "    [\"number_annotators\", \"annotators\",\"gender_annotators\",\"age_annotators\",\"labels_task1\",\"labels_task2\",\"labels_task3\",\"split\"],\n",
        "    axis=1\n",
        ")\n",
        "df_test_T1 = df_test_T1.drop(\n",
        "    [\"number_annotators\", \"annotators\",\"gender_annotators\",\"age_annotators\",\"labels_task1\",\"labels_task2\",\"labels_task3\",\"split\"],\n",
        "    axis=1\n",
        ")\n",
        "df_val_T1 = df_val_T1.drop(\n",
        "    [\"number_annotators\", \"annotators\",\"gender_annotators\",\"age_annotators\",\"labels_task1\",\"labels_task2\",\"labels_task3\",\"split\"],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Spanish tweets\n",
        "df_train_es = df_train_es.drop(\n",
        "    [\"number_annotators\", \"annotators\",\"gender_annotators\",\"age_annotators\",\"labels_task1\",\"labels_task2\",\"labels_task3\",\"split\"],\n",
        "    axis=1\n",
        ")\n",
        "df_test_es = df_test_es.drop(\n",
        "    [\"number_annotators\", \"annotators\",\"gender_annotators\",\"age_annotators\",\"labels_task1\",\"labels_task2\",\"labels_task3\",\"split\"],\n",
        "    axis=1\n",
        ")\n",
        "df_val_es = df_val_es.drop(\n",
        "    [\"number_annotators\", \"annotators\",\"gender_annotators\",\"age_annotators\",\"labels_task1\",\"labels_task2\",\"labels_task3\",\"split\"],\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJkepQDIIMD5"
      },
      "source": [
        "6. **Encode the `hard_label_task1` column**: Use 1 to represent \"YES\" and 0 to represent \"NO\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:06.328123Z",
          "iopub.status.busy": "2024-11-27T16:24:06.327805Z",
          "iopub.status.idle": "2024-11-27T16:24:06.335464Z",
          "shell.execute_reply": "2024-11-27T16:24:06.334537Z",
          "shell.execute_reply.started": "2024-11-27T16:24:06.328096Z"
        },
        "id": "vKsJaCIkIMD5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_train_T1['hard_labels_task1'] = df_train_T1['hard_labels_task1'].apply(lambda x: 1 if x == 'YES' else 0)\n",
        "df_test_T1['hard_labels_task1'] = df_test_T1['hard_labels_task1'].apply(lambda x: 1 if x == 'YES' else 0)\n",
        "df_val_T1['hard_labels_task1'] = df_val_T1['hard_labels_task1'].apply(lambda x: 1 if x == 'YES' else 0)\n",
        "\n",
        "\n",
        "df_train_es['hard_labels_task1'] = df_train_es['hard_labels_task1'].apply(lambda x: 1 if x == 'YES' else 0)\n",
        "df_test_es['hard_labels_task1'] = df_test_es['hard_labels_task1'].apply(lambda x: 1 if x == 'YES' else 0)\n",
        "df_val_es['hard_labels_task1'] = df_val_es['hard_labels_task1'].apply(lambda x: 1 if x == 'YES' else 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualisation"
      ],
      "metadata": {
        "id": "Hg-MhyUqUC5I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:06.943109Z",
          "iopub.status.busy": "2024-11-27T16:24:06.942342Z",
          "iopub.status.idle": "2024-11-27T16:24:06.951763Z",
          "shell.execute_reply": "2024-11-27T16:24:06.950870Z",
          "shell.execute_reply.started": "2024-11-27T16:24:06.943077Z"
        },
        "id": "giTrpXoHIMD6",
        "outputId": "b37cb586-3268-477f-abf2-4b78108996a9",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         lang                                              tweet  \\\n",
              "id_EXIST                                                           \n",
              "200002     en  Writing a uni essay in my local pub with a cof...   \n",
              "200003     en  @UniversalORL it is 2021 not 1921. I dont appr...   \n",
              "200006     en  According to a customer I have plenty of time ...   \n",
              "200007     en  So only 'blokes' drink beer? Sorry, but if you...   \n",
              "200008     en  New to the shelves this week - looking forward...   \n",
              "\n",
              "          hard_labels_task1  \n",
              "id_EXIST                     \n",
              "200002                    1  \n",
              "200003                    1  \n",
              "200006                    1  \n",
              "200007                    1  \n",
              "200008                    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2231c7c-dce7-4313-a7c3-d402573909a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lang</th>\n",
              "      <th>tweet</th>\n",
              "      <th>hard_labels_task1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_EXIST</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200002</th>\n",
              "      <td>en</td>\n",
              "      <td>Writing a uni essay in my local pub with a cof...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200003</th>\n",
              "      <td>en</td>\n",
              "      <td>@UniversalORL it is 2021 not 1921. I dont appr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200006</th>\n",
              "      <td>en</td>\n",
              "      <td>According to a customer I have plenty of time ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200007</th>\n",
              "      <td>en</td>\n",
              "      <td>So only 'blokes' drink beer? Sorry, but if you...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200008</th>\n",
              "      <td>en</td>\n",
              "      <td>New to the shelves this week - looking forward...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2231c7c-dce7-4313-a7c3-d402573909a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2231c7c-dce7-4313-a7c3-d402573909a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2231c7c-dce7-4313-a7c3-d402573909a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-03ed1195-ed16-425b-ab3a-c8b845ffb412\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03ed1195-ed16-425b-ab3a-c8b845ffb412')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-03ed1195-ed16-425b-ab3a-c8b845ffb412 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train_T1",
              "summary": "{\n  \"name\": \"df_train_T1\",\n  \"rows\": 2870,\n  \"fields\": [\n    {\n      \"column\": \"id_EXIST\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2870,\n        \"samples\": [\n          \"200504\",\n          \"202694\",\n          \"200852\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2870,\n        \"samples\": [\n          \"Call me sexist but it just feels wrong that women are reffing the NBA like go ref the WNBA\\ud83d\\ude2c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hard_labels_task1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df_train_T1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:10.775395Z",
          "iopub.status.busy": "2024-11-27T16:24:10.775037Z",
          "iopub.status.idle": "2024-11-27T16:24:10.780530Z",
          "shell.execute_reply": "2024-11-27T16:24:10.779661Z",
          "shell.execute_reply.started": "2024-11-27T16:24:10.775349Z"
        },
        "id": "8T7m7IjWIMD9",
        "outputId": "1d54f691-4be4-42dc-af7b-31ee08ca3dce",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English tweets \n",
            "\n",
            "- Training dataset shape: (2870, 3)\n",
            "- Test dataset shape: (286, 3)\n",
            "- Validation dataset shape: (158, 3)\n"
          ]
        }
      ],
      "source": [
        "print(\"English tweets \\n\")\n",
        "print(\"- Training dataset shape:\", df_train_T1.shape)\n",
        "print(\"- Test dataset shape:\", df_test_T1.shape)\n",
        "print(\"- Validation dataset shape:\", df_val_T1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "4DNCmnug3Klq",
        "outputId": "f79ffa97-f159-48d6-9f00-75ceb834ce6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         lang                                              tweet  \\\n",
              "id_EXIST                                                           \n",
              "100001     es  @TheChiflis Ignora al otro, es un capullo.El p...   \n",
              "100002     es  @ultimonomada_ Si comicsgate se parece en algo...   \n",
              "100003     es  @Steven2897 Lee sobre Gamergate, y como eso ha...   \n",
              "100005     es  @novadragon21 @icep4ck @TvDannyZ Entonces como...   \n",
              "100006     es  @yonkykong Aaah sí. Andrew Dobson. El que se d...   \n",
              "\n",
              "          hard_labels_task1  \n",
              "id_EXIST                     \n",
              "100001                    1  \n",
              "100002                    0  \n",
              "100003                    0  \n",
              "100005                    1  \n",
              "100006                    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed17fbb3-ff1f-4a79-aa36-3fcd6a5b5881\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lang</th>\n",
              "      <th>tweet</th>\n",
              "      <th>hard_labels_task1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_EXIST</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100001</th>\n",
              "      <td>es</td>\n",
              "      <td>@TheChiflis Ignora al otro, es un capullo.El p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100002</th>\n",
              "      <td>es</td>\n",
              "      <td>@ultimonomada_ Si comicsgate se parece en algo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100003</th>\n",
              "      <td>es</td>\n",
              "      <td>@Steven2897 Lee sobre Gamergate, y como eso ha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100005</th>\n",
              "      <td>es</td>\n",
              "      <td>@novadragon21 @icep4ck @TvDannyZ Entonces como...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100006</th>\n",
              "      <td>es</td>\n",
              "      <td>@yonkykong Aaah sí. Andrew Dobson. El que se d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed17fbb3-ff1f-4a79-aa36-3fcd6a5b5881')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed17fbb3-ff1f-4a79-aa36-3fcd6a5b5881 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed17fbb3-ff1f-4a79-aa36-3fcd6a5b5881');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-015e8337-e67c-4c4c-8073-e0981b8a6bdc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-015e8337-e67c-4c4c-8073-e0981b8a6bdc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-015e8337-e67c-4c4c-8073-e0981b8a6bdc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train_es",
              "summary": "{\n  \"name\": \"df_train_es\",\n  \"rows\": 3194,\n  \"fields\": [\n    {\n      \"column\": \"id_EXIST\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3194,\n        \"samples\": [\n          \"100659\",\n          \"100121\",\n          \"101276\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"es\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3194,\n        \"samples\": [\n          \"#Actualidad La brecha salarial de g\\u00e9nero impacta en la #Sanidad: ellas, ganan un 37% menos que ellos https://t.co/jmIKB5JJVT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hard_labels_task1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df_train_es.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBFVn96n3Klr",
        "outputId": "3889f6a2-51ed-4372-f04e-db8262a34848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spanish tweets \n",
            "\n",
            "- Training dataset shape: (3194, 3)\n",
            "- Test dataset shape: (0, 3)\n",
            "- Validation dataset shape: (490, 3)\n"
          ]
        }
      ],
      "source": [
        "print(\"Spanish tweets \\n\")\n",
        "print(\"- Training dataset shape:\", df_train_es.shape)\n",
        "print(\"- Test dataset shape:\", df_test_es.shape)\n",
        "print(\"- Validation dataset shape:\", df_val_es.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4fIRSia3Klr"
      },
      "source": [
        "As we can see from the previous output, **in the test set there are no spanish tweets**. Therefore, for the further computations and evaluations the validation set is used to test the models and the comparisons between the two languages are done by taking into consideration the corresponding validation sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "poPlvlZ7IMD-",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "# [Task2 - 0.5 points] Data Cleaning\n",
        "\n",
        "In the context of tweets, we have noisy and informal data that often includes unnecessary elements like emojis, hashtags, mentions, and URLs. These elements may interfere with the text analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "TWnsTwVzIMD_",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "\n",
        "\n",
        "### Instructions\n",
        "\n",
        "- **Remove emojis** from the tweets.\n",
        "\n",
        "- **Remove hashtags** (e.g., `#example`).\n",
        "\n",
        "- **Remove mentions** such as `@user`.\n",
        "\n",
        "- **Remove URLs** from the tweets.\n",
        "\n",
        "- **Remove special characters and symbols**.\n",
        "\n",
        "- **Remove specific quote characters** (e.g., curly quotes).\n",
        "\n",
        "- **Perform lemmatization** to reduce words to their base form."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RelnXeKF8VK-"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same cleaning procedure is applied on both the languages. In particular, for Spanish tweets an ad hoc lemmatization is applied, taken from the [**spaCy library**](https://spacy.io/models/es), where there are specific models to deal with different languages.\n",
        "\n"
      ],
      "metadata": {
        "id": "BVd20hBILHW3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:12.919230Z",
          "iopub.status.busy": "2024-11-27T16:24:12.918455Z",
          "iopub.status.idle": "2024-11-27T16:24:15.259852Z",
          "shell.execute_reply": "2024-11-27T16:24:15.258912Z",
          "shell.execute_reply.started": "2024-11-27T16:24:12.919197Z"
        },
        "id": "dgGgbSqpIMD_",
        "outputId": "a5c66f43-e290-4bcc-dea8-5f969f3707eb",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tagger_es = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "# This attempts to import a set of English and Spanish stopwords\n",
        "try:\n",
        "    STOPWORDS_EN = set(stopwords.words('english'))\n",
        "    STOPWORDS_ES = set(stopwords.words('spanish'))\n",
        "\n",
        "# If the stopwords resource is not found, it is dowloaded.\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "    STOPWORDS_EN = set(stopwords.words('english'))\n",
        "    STOPWORDS_ES = set(stopwords.words('spanish'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:15.262235Z",
          "iopub.status.busy": "2024-11-27T16:24:15.261927Z",
          "iopub.status.idle": "2024-11-27T16:24:15.280797Z",
          "shell.execute_reply": "2024-11-27T16:24:15.280142Z",
          "shell.execute_reply.started": "2024-11-27T16:24:15.262205Z"
        },
        "id": "g6B7w9ukIMEA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This function maps POS tags to WordNet POS tag\n",
        "# This is needed for using the WordNetLemmatizer()\n",
        "def get_wordnet_key(pos_tag):\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "\n",
        "\n",
        "# This function lemmatizes text using WordNet POS tagging\n",
        "def lem_text(text, lang='english'):\n",
        "    if lang=='english':\n",
        "        tokens = word_tokenize(text, language=lang)\n",
        "        tagged = pos_tag(tokens)\n",
        "        words = [lemmatizer.lemmatize(token, get_wordnet_key(tag)) for token, tag in tagged]\n",
        "    elif lang=='spanish':\n",
        "        tagged = tagger_es(text)\n",
        "        words = [token.lemma_ for token in tagged]\n",
        "    return \" \".join(words)\n",
        "\n",
        "\n",
        "# To remove emojis\n",
        "def strip_emoji(text):\n",
        "    RE_EMOJI = re.compile(u'([\\U00002600-\\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF])')\n",
        "    return RE_EMOJI.sub(r'', text)\n",
        "\n",
        "\n",
        "# To remove mentions, hashtags and punctuations.\n",
        "def strip_tags(text):\n",
        "    entity_prefixes = ['@','#']\n",
        "    words = []\n",
        "    for word in text.split():\n",
        "        word = word.strip()\n",
        "        if word:\n",
        "            if word[0] not in entity_prefixes:\n",
        "                if entity_prefixes[0] in word:\n",
        "                    idx = word.find(entity_prefixes[0])\n",
        "                    words.append(word[:idx])\n",
        "                elif entity_prefixes[1] in word:\n",
        "                    idx = word.find(entity_prefixes[1])\n",
        "                    words.append(word[:idx])\n",
        "                else:\n",
        "                    words.append(word)\n",
        "    return ' '.join(words)\n",
        "\n",
        "\n",
        "# To remove all links (URLs)\n",
        "def remove_links(text):\n",
        "    # Regular expression pattern to match URLs\n",
        "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "    return re.sub(url_pattern, '', text)\n",
        "\n",
        "\n",
        "# To remove special characters and symbols\n",
        "def special_ch_sym(text):\n",
        "    RE_ch_sym = re.compile(u'[^a-z A-Z 0-9 À-ú]')\n",
        "    return RE_ch_sym.sub(r' ',text)\n",
        "\n",
        "\n",
        "# To remove \"br\" characters\n",
        "def replace_br(text):\n",
        "    return text.replace('<br>', ' ')\n",
        "\n",
        "\n",
        "# To remove stopwords\n",
        "def remove_stopwords(text, stopwords):\n",
        "    return ' '.join([x for x in text.split() if x and x not in stopwords])\n",
        "\n",
        "\n",
        "# All the functions are then applied to the text\n",
        "def text_cleaning_en(text):\n",
        "    return lem_text(remove_stopwords(replace_br(special_ch_sym(strip_tags(remove_links(strip_emoji(text.lower().strip()))))), STOPWORDS_EN), 'english')\n",
        "\n",
        "def text_cleaning_es(text):\n",
        "    return lem_text(remove_stopwords(replace_br(special_ch_sym(strip_tags(remove_links(strip_emoji(text.lower().strip()))))), STOPWORDS_ES), 'spanish')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:15.281936Z",
          "iopub.status.busy": "2024-11-27T16:24:15.281716Z",
          "iopub.status.idle": "2024-11-27T16:24:20.324231Z",
          "shell.execute_reply": "2024-11-27T16:24:20.323406Z",
          "shell.execute_reply.started": "2024-11-27T16:24:15.281913Z"
        },
        "id": "PAZjiKLhIMEB",
        "outputId": "f0fdff4c-7570-4c18-a802-cba8e496d588",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         lang                                              tweet  \\\n",
              "id_EXIST                                                           \n",
              "200002     en  write uni essay local pub coffee random old ma...   \n",
              "200003     en  2021 1921 dont appreciate two ride team member...   \n",
              "200006     en  accord customer plenty time go spent stirling ...   \n",
              "200007     en  bloke drink beer sorry bloke drink wine appare...   \n",
              "200008     en              new shelf week look forward read book   \n",
              "\n",
              "          hard_labels_task1  \n",
              "id_EXIST                     \n",
              "200002                    1  \n",
              "200003                    1  \n",
              "200006                    1  \n",
              "200007                    1  \n",
              "200008                    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a42ec241-3e64-4311-a173-45734af0503f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lang</th>\n",
              "      <th>tweet</th>\n",
              "      <th>hard_labels_task1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_EXIST</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200002</th>\n",
              "      <td>en</td>\n",
              "      <td>write uni essay local pub coffee random old ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200003</th>\n",
              "      <td>en</td>\n",
              "      <td>2021 1921 dont appreciate two ride team member...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200006</th>\n",
              "      <td>en</td>\n",
              "      <td>accord customer plenty time go spent stirling ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200007</th>\n",
              "      <td>en</td>\n",
              "      <td>bloke drink beer sorry bloke drink wine appare...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200008</th>\n",
              "      <td>en</td>\n",
              "      <td>new shelf week look forward read book</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a42ec241-3e64-4311-a173-45734af0503f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a42ec241-3e64-4311-a173-45734af0503f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a42ec241-3e64-4311-a173-45734af0503f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a0c830d0-eed7-4722-820c-99c920556128\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a0c830d0-eed7-4722-820c-99c920556128')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a0c830d0-eed7-4722-820c-99c920556128 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train_T2",
              "summary": "{\n  \"name\": \"df_train_T2\",\n  \"rows\": 2870,\n  \"fields\": [\n    {\n      \"column\": \"id_EXIST\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2870,\n        \"samples\": [\n          \"200504\",\n          \"202694\",\n          \"200852\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2867,\n        \"samples\": [\n          \"call sexist feel wrong woman reffing nba like go ref wnba\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hard_labels_task1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# df_train_T1 -> It contains the original tweets\n",
        "# df_train_T2 -> It contains the cleaned tweets\n",
        "\n",
        "df_train_T2 = df_train_T1.copy()\n",
        "df_train_T2['tweet'] = df_train_T2['tweet'].apply(text_cleaning_en)\n",
        "\n",
        "df_test_T2 = df_test_T1.copy()\n",
        "df_test_T2['tweet'] = df_test_T2['tweet'].apply(text_cleaning_en)\n",
        "\n",
        "df_val_T2 = df_val_T1.copy()\n",
        "df_val_T2['tweet'] = df_val_T2['tweet'].apply(text_cleaning_en)\n",
        "\n",
        "df_train_T2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "oc2Dzvzv3Klv",
        "outputId": "aec3616d-3deb-481d-f30b-13262bdb21f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         lang                                              tweet  \\\n",
              "id_EXIST                                                           \n",
              "100001     es  ignorar capullo problema youtuber denunciar ac...   \n",
              "100002     es  si comicsgate parecer gamergate pues bien acos...   \n",
              "100003     es  leer gamergate cambiado manera comunicar inter...   \n",
              "100005     es  entonces así mercado mejor hacer cambiar él se...   \n",
              "100006     es  aaah andrew dobson dedicar echar mierdo gamerg...   \n",
              "\n",
              "          hard_labels_task1  \n",
              "id_EXIST                     \n",
              "100001                    1  \n",
              "100002                    0  \n",
              "100003                    0  \n",
              "100005                    1  \n",
              "100006                    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-805fed76-7887-43ce-aeb7-f9780d775a8b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lang</th>\n",
              "      <th>tweet</th>\n",
              "      <th>hard_labels_task1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id_EXIST</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100001</th>\n",
              "      <td>es</td>\n",
              "      <td>ignorar capullo problema youtuber denunciar ac...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100002</th>\n",
              "      <td>es</td>\n",
              "      <td>si comicsgate parecer gamergate pues bien acos...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100003</th>\n",
              "      <td>es</td>\n",
              "      <td>leer gamergate cambiado manera comunicar inter...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100005</th>\n",
              "      <td>es</td>\n",
              "      <td>entonces así mercado mejor hacer cambiar él se...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100006</th>\n",
              "      <td>es</td>\n",
              "      <td>aaah andrew dobson dedicar echar mierdo gamerg...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-805fed76-7887-43ce-aeb7-f9780d775a8b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-805fed76-7887-43ce-aeb7-f9780d775a8b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-805fed76-7887-43ce-aeb7-f9780d775a8b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5c7a67c9-e68c-475d-b0f5-d8f805b05693\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c7a67c9-e68c-475d-b0f5-d8f805b05693')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5c7a67c9-e68c-475d-b0f5-d8f805b05693 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train_clean_es",
              "summary": "{\n  \"name\": \"df_train_clean_es\",\n  \"rows\": 3194,\n  \"fields\": [\n    {\n      \"column\": \"id_EXIST\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3194,\n        \"samples\": [\n          \"100659\",\n          \"100121\",\n          \"101276\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"es\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3168,\n        \"samples\": [\n          \"pues mil vez putisimo mojigata\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hard_labels_task1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df_train_clean_es = df_train_es.copy()\n",
        "df_train_clean_es['tweet'] = df_train_clean_es['tweet'].apply(text_cleaning_es)\n",
        "\n",
        "df_val_clean_es = df_val_es.copy()\n",
        "df_val_clean_es['tweet'] = df_val_clean_es['tweet'].apply(text_cleaning_es)\n",
        "\n",
        "df_train_clean_es.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3KylLHNl0bE"
      },
      "source": [
        "# [Task 3 - 0.5 points] Text Encoding\n",
        "\n",
        "To train a neural sexism classifier, you first need to encode text into numerical format.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr1lTHUVOXff"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "\n",
        "\n",
        "* Embed words using **GloVe embeddings**.\n",
        "\n",
        "* You are **free** to pick any embedding dimension.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6NNMEjWOZQr"
      },
      "source": [
        "### Note : What about OOV tokens?\n",
        "\n",
        "   * All the tokens in the **training** set that are not in GloVe **must** be added to the vocabulary.\n",
        "\n",
        "   * For the remaining tokens (i.e., OOV in the validation and test sets), you have to assign them a **special token** (e.g., [UNK]) and a **static** embedding.\n",
        "\n",
        "   * You are **free** to define the static embedding using any strategy (e.g., random, neighbourhood, etc...)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90UztlGUObXk"
      },
      "source": [
        "### More about OOV\n",
        "\n",
        "\n",
        "\n",
        "For a given token:\n",
        "\n",
        "\n",
        "\n",
        "* **If in train set**: add to vocabulary and assign an embedding (use GloVe if token in GloVe, custom embedding otherwise).\n",
        "\n",
        "* **If in val/test set**: assign special token if not in vocabulary and assign custom embedding.\n",
        "\n",
        "\n",
        "\n",
        "Your vocabulary **should**:\n",
        "\n",
        "\n",
        "\n",
        "* Contain all tokens in train set; or\n",
        "\n",
        "* Union of tokens in train set and in GloVe $\\rightarrow$ we make use of existing knowledge!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzybqGG08VLC"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGptfUqyIMEE"
      },
      "source": [
        "1. **Building a vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:20.332432Z",
          "iopub.status.busy": "2024-11-27T16:24:20.332081Z",
          "iopub.status.idle": "2024-11-27T16:24:20.348612Z",
          "shell.execute_reply": "2024-11-27T16:24:20.347836Z",
          "shell.execute_reply.started": "2024-11-27T16:24:20.332389Z"
        },
        "id": "7vnDEZx3IMEE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def build_vocabulary(df, lang='english'):\n",
        "    idx_to_word = OrderedDict()\n",
        "    word_to_idx = OrderedDict()\n",
        "    curr_idx = 0\n",
        "\n",
        "    # \"<pad>\" it the first element of the dictionary\n",
        "    word_to_idx['<pad>'] = curr_idx\n",
        "    idx_to_word[curr_idx] = '<pad>'\n",
        "    curr_idx += 1\n",
        "\n",
        "    for sentence in df.tweet.values:\n",
        "        tokens = word_tokenize(sentence, language=lang)\n",
        "        for token in tokens:\n",
        "            if token not in word_to_idx:\n",
        "                word_to_idx[token] = curr_idx\n",
        "                idx_to_word[curr_idx] = token\n",
        "                curr_idx += 1\n",
        "\n",
        "    # \"<unk>\" it the last element of the dictionary\n",
        "    word_to_idx['<unk>'] = curr_idx\n",
        "    idx_to_word[curr_idx] = '<unk>'\n",
        "\n",
        "    word_listing = list(idx_to_word.values())\n",
        "\n",
        "    return idx_to_word, word_to_idx, word_listing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:20.594524Z",
          "iopub.status.busy": "2024-11-27T16:24:20.594166Z",
          "iopub.status.idle": "2024-11-27T16:24:21.836103Z",
          "shell.execute_reply": "2024-11-27T16:24:21.835264Z",
          "shell.execute_reply.started": "2024-11-27T16:24:20.594495Z"
        },
        "id": "_fw0J8NtIMEP",
        "outputId": "992e4343-69e2-414e-d864-db03279ce0ba",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocabulary\n",
            "\n",
            "Index -> Word vocabulary size: 9009\n",
            "Word -> Index vocabulary size: 9009\n",
            "Some words: [('<pad>', 0), ('write', 1), ('uni', 2), ('essay', 3), ('local', 4), ('pub', 5), ('coffee', 6), ('random', 7), ('old', 8), ('man', 9)]\n"
          ]
        }
      ],
      "source": [
        "idx_to_word_en, word_to_idx_en, word_listing_en = build_vocabulary(df_train_T2)\n",
        "vocab_size_en = len(idx_to_word_en)\n",
        "\n",
        "print('English Vocabulary\\n')\n",
        "print(f'Index -> Word vocabulary size: {len(idx_to_word_en)}')\n",
        "print(f'Word -> Index vocabulary size: {len(word_to_idx_en)}')\n",
        "print(f'Some words: {[(idx_to_word_en[idx], idx) for idx in np.arange(0, 10)]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqekLu_d3Kl0",
        "outputId": "cb742ded-4657-4c6b-ef27-b5383f72e270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spanish Vocabulary \n",
            "\n",
            "Index -> Word vocabulary size: 11587\n",
            "Word -> Index vocabulary size: 11587\n",
            "Some words: [('<pad>', 0), ('ignorar', 1), ('capullo', 2), ('problema', 3), ('youtuber', 4), ('denunciar', 5), ('acoso', 6), ('afectar', 7), ('gente', 8), ('izquierdo', 9)]\n"
          ]
        }
      ],
      "source": [
        "idx_to_word_es, word_to_idx_es, word_listing_es = build_vocabulary(df_train_clean_es, 'spanish')\n",
        "vocab_size_es = len(idx_to_word_es)\n",
        "\n",
        "print('Spanish Vocabulary \\n')\n",
        "print(f'Index -> Word vocabulary size: {len(idx_to_word_es)}')\n",
        "print(f'Word -> Index vocabulary size: {len(word_to_idx_es)}')\n",
        "print(f'Some words: {[(idx_to_word_es[idx], idx) for idx in np.arange(0, 10)]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:21.838428Z",
          "iopub.status.busy": "2024-11-27T16:24:21.837768Z",
          "iopub.status.idle": "2024-11-27T16:24:21.843922Z",
          "shell.execute_reply": "2024-11-27T16:24:21.843140Z",
          "shell.execute_reply.started": "2024-11-27T16:24:21.838387Z"
        },
        "id": "0JpFNaEKIMEP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def evaluate_vocabulary(idx_to_word, word_to_idx, word_listing, df, check_default_size: bool = False):\n",
        "\n",
        "    print(\"  [Vocabulary Evaluation] Size checking...\")\n",
        "    assert len(idx_to_word) == len(word_to_idx)\n",
        "    assert len(idx_to_word) == len(word_listing)\n",
        "\n",
        "    print(\"  [Vocabulary Evaluation] Content checking...\")\n",
        "    for i in range(0, len(idx_to_word)):\n",
        "        assert idx_to_word[i] in word_to_idx\n",
        "        assert word_to_idx[idx_to_word[i]] == i\n",
        "\n",
        "    print(\"  [Vocabulary Evaluation] Consistency checking...\")\n",
        "    _, _, first_word_listing = build_vocabulary(df)\n",
        "    _, _, second_word_listing = build_vocabulary(df)\n",
        "    assert first_word_listing == second_word_listing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-11-27T16:24:22.890625Z",
          "iopub.status.busy": "2024-11-27T16:24:22.889776Z",
          "iopub.status.idle": "2024-11-27T16:24:25.369496Z",
          "shell.execute_reply": "2024-11-27T16:24:25.368633Z",
          "shell.execute_reply.started": "2024-11-27T16:24:22.890590Z"
        },
        "id": "eYzPqdmvIMEP",
        "outputId": "eae7a272-9334-4830-9588-d8bafe540c6b",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary evaluation...\n",
            "  [Vocabulary Evaluation] Size checking...\n",
            "  [Vocabulary Evaluation] Content checking...\n",
            "  [Vocabulary Evaluation] Consistency checking...\n",
            "\n",
            "Evaluation completed!\n"
          ]
        }
      ],
      "source": [
        "print(\"Vocabulary evaluation...\")\n",
        "evaluate_vocabulary(idx_to_word_en, word_to_idx_en, word_listing_en, df_train_T2)\n",
        "print(\"\\nEvaluation completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9JGCrtB3Kl1",
        "outputId": "2d046075-0cb0-467f-a1b2-3ede10e9d9c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary evaluation...\n",
            "  [Vocabulary Evaluation] Size checking...\n",
            "  [Vocabulary Evaluation] Content checking...\n",
            "  [Vocabulary Evaluation] Consistency checking...\n",
            "\n",
            "Evaluation completed!\n"
          ]
        }
      ],
      "source": [
        "print(\"Vocabulary evaluation...\")\n",
        "evaluate_vocabulary(idx_to_word_es, word_to_idx_es, word_listing_es, df_train_clean_es)\n",
        "print(\"\\nEvaluation completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzbltyt9IMEP"
      },
      "source": [
        "2. **Embedding**\n",
        "\n",
        "For the English tweets the choice has been a GloVe embedding model in the `gensim` library that is already trained on **Twitter** [*(glove-twitter-100)*](https://github.com/piskvorky/gensim-data). On the other hand, the availability of models for Spanish is not as big as English, even if there are a lot of valuable alternatives. The choice in this case has been a FastText embedding model, with embedding dimension 100, trained on the **Spanish Unannotated Corpora (SUC)** [*(spanish-word-embeddings)*](https://github.com/dccuchile/spanish-word-embeddings/blob/master/emb-from-suc.md)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T16:25:35.939922Z",
          "iopub.status.busy": "2024-11-27T16:25:35.939584Z"
        },
        "id": "_rDd6Q8bIMEP",
        "trusted": true,
        "outputId": "6b270559-7aff-4b7a-b568-bb70048fc869",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "embedding_dimension = 100\n",
        "glove_model = gloader.load(\"glove-twitter-{}\".format(embedding_dimension))\n",
        "spanish_model = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(\"spanish_embed.vec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuTJamcRIMEP"
      },
      "source": [
        "3. **Out of vocabulary (OOV) words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T16:28:39.631169Z",
          "iopub.status.busy": "2024-11-27T16:28:39.630568Z",
          "iopub.status.idle": "2024-11-27T16:28:39.635207Z",
          "shell.execute_reply": "2024-11-27T16:28:39.634347Z",
          "shell.execute_reply.started": "2024-11-27T16:28:39.631139Z"
        },
        "id": "oINwUZo4IMEP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This returns a list of all those in the training set that are not in GloVe\n",
        "def check_OOV_terms(embedding_model: gensim.models.keyedvectors.KeyedVectors, word_listing):\n",
        "\n",
        "    embedding_vocabulary = set(embedding_model.key_to_index.keys())\n",
        "    oov = set(word_listing).difference(embedding_vocabulary)\n",
        "\n",
        "    return list(oov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-11-27T16:28:43.159081Z",
          "iopub.status.busy": "2024-11-27T16:28:43.158754Z",
          "iopub.status.idle": "2024-11-27T16:28:43.210014Z",
          "shell.execute_reply": "2024-11-27T16:28:43.209102Z",
          "shell.execute_reply.started": "2024-11-27T16:28:43.159054Z"
        },
        "id": "uM43ruGPIMEP",
        "outputId": "99872363-51fe-48db-b947-cb6a9c9c2765",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOV terms (English GloVe): 1046 (11.61%)\n"
          ]
        }
      ],
      "source": [
        "oov_terms_glove = check_OOV_terms(glove_model, word_listing_en)\n",
        "oov_percentage_glove = float(len(oov_terms_glove)) * 100 / len(word_listing_en)\n",
        "\n",
        "print(f\"OOV terms (English GloVe): {len(oov_terms_glove)} ({oov_percentage_glove:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSyqUMkm3Kl6",
        "outputId": "d4ab8923-e6e1-4f73-e740-2bcfcb064f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOV terms (Spanish FastText): 1633 (14.09%)\n"
          ]
        }
      ],
      "source": [
        "oov_terms_es = check_OOV_terms(spanish_model, word_listing_es)\n",
        "oov_percentage_es = float(len(oov_terms_es)) * 100 / len(word_listing_es)\n",
        "\n",
        "print(f\"OOV terms (Spanish FastText): {len(oov_terms_es)} ({oov_percentage_es:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZUvWQaK3Kl6"
      },
      "source": [
        "4. **Building the Embedding Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T16:28:44.253281Z",
          "iopub.status.busy": "2024-11-27T16:28:44.252677Z",
          "iopub.status.idle": "2024-11-27T16:28:44.259251Z",
          "shell.execute_reply": "2024-11-27T16:28:44.258177Z",
          "shell.execute_reply.started": "2024-11-27T16:28:44.253248Z"
        },
        "id": "AyvSWOBTIMEP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def build_embedding_matrix(embedding_model, embedding_dimension, word_to_idx, vocab_size):\n",
        "\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dimension), dtype=np.float32)\n",
        "    for word, idx in word_to_idx.items():\n",
        "\n",
        "        # For each word in the training set, an embedding vector is created by GloVe\n",
        "        try:\n",
        "            embedding_vector = embedding_model[word]\n",
        "\n",
        "        # If the word is not present, it must be added\n",
        "        except (KeyError, TypeError):\n",
        "            if word == \"<unk>\":\n",
        "                # To \"<unk>\" a vector of all zeros is set\n",
        "                embedding_vector = np.zeros(embedding_dimension)\n",
        "\n",
        "            else:\n",
        "                # To all the other words a random vector is set\n",
        "                embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n",
        "\n",
        "        embedding_matrix[idx] = embedding_vector\n",
        "\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76uKIsM63Kl7"
      },
      "source": [
        "An **embedding matrix** is built for each of the embedding model used, starting from the *English* and *Spanish vocabulary* previously defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-11-27T16:28:45.048670Z",
          "iopub.status.busy": "2024-11-27T16:28:45.048270Z",
          "iopub.status.idle": "2024-11-27T16:28:45.084895Z",
          "shell.execute_reply": "2024-11-27T16:28:45.084119Z",
          "shell.execute_reply.started": "2024-11-27T16:28:45.048625Z"
        },
        "id": "zhTVv4ejIMEP",
        "outputId": "07a9c9f1-b0dc-4267-f499-2225f9b40ee3",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Embedding matrix shape: (9009, 100)\n"
          ]
        }
      ],
      "source": [
        "embed_matrix_glove = build_embedding_matrix(glove_model,\n",
        "                                          embedding_dimension,\n",
        "                                          word_to_idx_en,\n",
        "                                          vocab_size_en)\n",
        "\n",
        "print(f\"\\nEmbedding matrix shape: {embed_matrix_glove.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_matrix_spanish = build_embedding_matrix(spanish_model,\n",
        "                                              embedding_dimension,\n",
        "                                              word_to_idx_es,\n",
        "                                              vocab_size_es)\n",
        "\n",
        "print(f\"\\nEmbedding matrix shape: {embed_matrix_spanish.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMtofWDz5-7a",
        "outputId": "d7eb78d8-1293-450a-de61-ced5828b7e5b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Embedding matrix shape: (11587, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References:\n",
        "\n",
        "- Bojanowski, Piotr, et al. \"Enriching word vectors with subword information.\" *Transactions of the association for computational linguistics* 5 (2017): 135-146."
      ],
      "metadata": {
        "id": "CI0iFAamBM0b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JLnuLGHGAUT"
      },
      "source": [
        "# [Task 4 - 1.0 points] Model definition\n",
        "\n",
        "\n",
        "\n",
        "You are now tasked to define your sexism classifier.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQFI9J-JOfXD"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "\n",
        "\n",
        "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
        "\n",
        "* You are **free** to experiment with hyper-parameters to define the baseline model.\n",
        "\n",
        "\n",
        "\n",
        "* **Model 1**: add an additional LSTM layer to the Baseline model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jALc_qYGS2E"
      },
      "source": [
        "### Token to embedding mapping\n",
        "\n",
        "\n",
        "\n",
        "You can follow two approaches for encoding tokens in your classifier.\n",
        "\n",
        "\n",
        "\n",
        "### Work directly with embeddings\n",
        "\n",
        "\n",
        "\n",
        "- Compute the embedding of each input token\n",
        "\n",
        "- Feed the mini-batches of shape (batch_size, # tokens, embedding_dim) to your model\n",
        "\n",
        "\n",
        "\n",
        "### Work with Embedding layer\n",
        "\n",
        "\n",
        "\n",
        "- Encode input tokens to token ids\n",
        "\n",
        "- Define a Embedding layer as the first layer of your model\n",
        "\n",
        "- Compute the embedding matrix of all known tokens (i.e., tokens in your vocabulary)\n",
        "\n",
        "- Initialize the Embedding layer with the computed embedding matrix\n",
        "\n",
        "- You are **free** to set the Embedding layer trainable or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEQTPu6eGgGv"
      },
      "source": [
        "### Padding\n",
        "\n",
        "\n",
        "\n",
        "Pay attention to padding tokens!\n",
        "\n",
        "\n",
        "\n",
        "Your model **should not** be penalized on those tokens.\n",
        "\n",
        "\n",
        "\n",
        "#### How to?\n",
        "\n",
        "\n",
        "\n",
        "There are two main ways.\n",
        "\n",
        "\n",
        "\n",
        "However, their implementation depends on the neural library you are using.\n",
        "\n",
        "\n",
        "\n",
        "- Embedding layer\n",
        "\n",
        "- Custom loss to compute average cross-entropy on non-padding tokens only\n",
        "\n",
        "\n",
        "\n",
        "**Note**: This is a **recommendation**, but we **do not penalize** for missing workarounds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89shXTKm8VLE"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T14:47:56.749736Z",
          "iopub.status.busy": "2024-11-27T14:47:56.749019Z",
          "iopub.status.idle": "2024-11-27T14:47:57.037477Z",
          "shell.execute_reply": "2024-11-27T14:47:57.036568Z",
          "shell.execute_reply.started": "2024-11-27T14:47:56.749701Z"
        },
        "id": "G--DBzY-E59v",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ----- Hyperparameters ----- #\n",
        "\n",
        "hidden_dim = 64\n",
        "num_classes = 2\n",
        "max_len_en = max(df_train_T2['tweet'].apply(lambda x: len(word_tokenize(x))))\n",
        "max_len_es = max(df_train_es['tweet'].apply(lambda x: len(word_tokenize(x, language='spanish'))))\n",
        "seeds = [42, 347, 1337]\n",
        "batch_size = 16\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T14:48:04.031629Z",
          "iopub.status.busy": "2024-11-27T14:48:04.030785Z",
          "iopub.status.idle": "2024-11-27T14:48:04.040991Z",
          "shell.execute_reply": "2024-11-27T14:48:04.040111Z",
          "shell.execute_reply.started": "2024-11-27T14:48:04.031595Z"
        },
        "id": "1FkUxGfj8TOb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "@keras.saving.register_keras_serializable()\n",
        "\n",
        "class Bidirectional_LSTM (tf.keras.Model):\n",
        "\n",
        "    # input_dim: Lenght of the input tweets.\n",
        "    # hidden_dim: Dimensionality of the hidden layers in the LSTMs.\n",
        "    # num_layers: Number of stacked bidirectional LSTM layers. Default value is 1.\n",
        "        # 1 --> Baseline LSTM\n",
        "        # 2 --> Model 1 LSTM\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, vocab_size, embedding_matrix, num_layers = 1, name=None, **kwargs):\n",
        "        super(Bidirectional_LSTM, self).__init__(**kwargs)\n",
        "\n",
        "        self.name = name\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.input_dim = input_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_matrix = embedding_matrix\n",
        "\n",
        "        # To map integer tokens to dense vectors\n",
        "        self.embed_layer = Embedding(input_dim=self.vocab_size,\n",
        "                                      output_dim=embedding_dimension,\n",
        "                                      weights=[self.embedding_matrix],\n",
        "                                      mask_zero=True,   # automatically masks padding tokens\n",
        "                                      name='encoder_embedding')\n",
        "\n",
        "        # First bidirectional LSTM layer - Baseline\n",
        "        self.bidir_layer_1 = Bidirectional(LSTM(hidden_dim), backward_layer=LSTM(hidden_dim, go_backwards=True))\n",
        "        self.bidir_layers_2 = []\n",
        "\n",
        "        # Additional bidirectional LSTM layers - Model 1\n",
        "        for i in range(num_layers-1):\n",
        "            self.bidir_layers_2.append(Bidirectional(LSTM(hidden_dim, return_sequences=True),\n",
        "                                                     backward_layer=LSTM(hidden_dim, go_backwards=True, return_sequences=True)))\n",
        "\n",
        "        # Dense output layer\n",
        "        self.dense_layer = Dense(output_dim, activation='softmax')\n",
        "\n",
        "\n",
        "\n",
        "    def build(self):\n",
        "        # Call the model with a random input to define its shape\n",
        "        self.call(keras.random.normal((self.input_dim, 1)))\n",
        "        self.built = True\n",
        "\n",
        "\n",
        "\n",
        "    # Forward pass of the model\n",
        "    def call(self, input):\n",
        "        x = self.embed_layer(input)\n",
        "        for idx, layer in enumerate(self.bidir_layers_2):\n",
        "            x = layer(x)\n",
        "        x = self.bidir_layer_1(x)\n",
        "        output = self.dense_layer(x)\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "    #method for the serialization of the model\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"input_dim\" : self.input_dim,\n",
        "            \"output_dim\" : self.output_dim,\n",
        "            \"hidden_dim\" : self.hidden_dim,\n",
        "            \"num_layers\" : self.num_layers,\n",
        "            \"name\" : self.name,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualisation of the number of parameters"
      ],
      "metadata": {
        "id": "JblUMr4sxPFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_LSTM = Bidirectional_LSTM(input_dim=max_len_en,\n",
        "                                   output_dim=num_classes,\n",
        "                                   hidden_dim=hidden_dim,\n",
        "                                   vocab_size=vocab_size_en,\n",
        "                                   embedding_matrix=embed_matrix_glove,\n",
        "                                   num_layers=1,\n",
        "                                   name=\"Baseline_LSTM\")\n",
        "baseline_LSTM.compile(optimizer=Nadam(ema_momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "baseline_LSTM.build()\n",
        "baseline_LSTM.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "OGi1O_SA_HsJ",
        "outputId": "1cef7df9-f3e5-41d1-baba-6b1a102affb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Baseline_LSTM\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Baseline_LSTM\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_embedding (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                           │       \u001b[38;5;34m2,700,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_20 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   │         \u001b[38;5;34m186,880\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m2\u001b[0m)                     │             \u001b[38;5;34m258\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,700,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,887,138\u001b[0m (11.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,887,138</span> (11.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,887,138\u001b[0m (11.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,887,138</span> (11.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_LSTM = Bidirectional_LSTM(input_dim=max_len_en,\n",
        "                                  output_dim=num_classes,\n",
        "                                  hidden_dim=hidden_dim,\n",
        "                                  vocab_size=vocab_size_en,\n",
        "                                  embedding_matrix=embed_matrix_glove,\n",
        "                                  num_layers=2,\n",
        "                                  name=\"Model_1_LSTM\")\n",
        "model_1_LSTM.compile(optimizer=Nadam(ema_momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_1_LSTM.build()\n",
        "model_1_LSTM.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "y8WiwvA2_b7j",
        "outputId": "0ac00e6a-54b7-4ada-8396-e5621ee21578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Model_1_LSTM\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Model_1_LSTM\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_embedding (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                           │       \u001b[38;5;34m2,700,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_21 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   │          \u001b[38;5;34m98,816\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_22 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)                │         \u001b[38;5;34m186,880\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m2\u001b[0m)                     │             \u001b[38;5;34m258\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,700,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,985,954\u001b[0m (11.39 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,985,954</span> (11.39 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,985,954\u001b[0m (11.39 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,985,954</span> (11.39 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W91gkqsFQ_u"
      },
      "source": [
        "## References:\n",
        "\n",
        "* Zeyer, Albert, et al. \"A comprehensive study of deep bidirectional LSTM RNNs for acoustic modeling in speech recognition.\" *2017 IEEE international conference on acoustics, speech and signal processing (ICASSP).* IEEE, 2017."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFjBgdiRG3wD"
      },
      "source": [
        "# [Task 5 - 1.0 points] Training and Evaluation\n",
        "\n",
        "\n",
        "\n",
        "You are now tasked to train and evaluate the Baseline and Model 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWPK4umGOjtT"
      },
      "source": [
        "\n",
        "\n",
        "### Instructions\n",
        "\n",
        "\n",
        "\n",
        "* Train **all** models on the train set.\n",
        "\n",
        "* Evaluate **all** models on the validation set.\n",
        "\n",
        "* Compute metrics on the validation set.\n",
        "\n",
        "* Pick **at least** three seeds for robust estimation.\n",
        "\n",
        "* Pick the **best** performing model according to the observed validation set performance.\n",
        "\n",
        "* Evaluate your models using macro F1-score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GmUOQJb8VLF"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQGT_YRiBfqv"
      },
      "source": [
        "## Training\n",
        "\n",
        "Both the `Baseline LSTM` and the `Model 1 LSTM` models have been trained and evaluated using three different random seeds. For each model, we have picked the best instance, with the related seed, which has been evaluated on the _test set_ for single model performances and overall performaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T14:49:00.028648Z",
          "iopub.status.busy": "2024-11-27T14:49:00.027795Z",
          "iopub.status.idle": "2024-11-27T14:49:00.034544Z",
          "shell.execute_reply": "2024-11-27T14:49:00.033629Z",
          "shell.execute_reply.started": "2024-11-27T14:49:00.028615Z"
        },
        "id": "-9ODTggnxlh0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Callback to compute the F1 score at the end of each epoch.\n",
        "\n",
        "class F1ScoreCallback(Callback):\n",
        "\n",
        "    # it takes the DataGenerator for validation data\n",
        "    def __init__(self, validation_generator):\n",
        "        super(F1ScoreCallback, self).__init__()\n",
        "\n",
        "        self.validation_generator = validation_generator\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Accumulate predictions and true labels across all validation batches\n",
        "        all_predictions = []\n",
        "        all_true_labels = []\n",
        "\n",
        "        for i in range(len(self.validation_generator)):\n",
        "\n",
        "            # Fetch the next batch of validation data\n",
        "            val_inputs, val_labels = self.validation_generator[i]\n",
        "\n",
        "            # Predict on the batch\n",
        "            batch_predictions = np.argmax(self.model.predict(val_inputs, verbose=0), axis=-1)\n",
        "            val_labels = np.argmax(val_labels, axis=1)\n",
        "\n",
        "            # Collect predictions and true labels\n",
        "            all_predictions.append(batch_predictions)\n",
        "            all_true_labels.append(val_labels)\n",
        "\n",
        "        # Compute F1 score\n",
        "        f1 = f1_score(all_true_labels, all_predictions, average='macro')\n",
        "\n",
        "        # Log the F1 score\n",
        "        logs['f1_score'] = f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T14:49:00.632556Z",
          "iopub.status.busy": "2024-11-27T14:49:00.631837Z",
          "iopub.status.idle": "2024-11-27T14:49:00.641332Z",
          "shell.execute_reply": "2024-11-27T14:49:00.640452Z",
          "shell.execute_reply.started": "2024-11-27T14:49:00.632525Z"
        },
        "id": "MTs6dZfcWsaz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class DataGenerator(Sequence):\n",
        "\n",
        "    def __init__(self, data, word_to_idx, word_listing, max_len, lang='english', batch_size=16, shuffle=True, seed=seed):\n",
        "        super().__init__()\n",
        "\n",
        "        self.data = data\n",
        "        self.tweet = data[\"tweet\"].to_numpy()\n",
        "        self.hard_labels_task1 = data[\"hard_labels_task1\"]\n",
        "        self.word_to_idx = word_to_idx\n",
        "        self.word_listing = word_listing\n",
        "        self.max_len = max_len\n",
        "        self.lang = lang\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.seed = seed\n",
        "        self.on_epoch_end()\n",
        "        self._prepare_data()\n",
        "\n",
        "\n",
        "\n",
        "    # Number of batches in the dataset\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.data) / self.batch_size))\n",
        "\n",
        "\n",
        "\n",
        "    # It returns a batch of data and its corresponding target labels\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        indexes = self.indexes[index*self.batch_size: (index+1)*self.batch_size]\n",
        "        data_batch = np.array([self.tweet[k] for k in indexes])\n",
        "        target_batch = np.array([[1, 0] if self.hard_labels_task1.to_list()[k]==0 else [0, 1] for k in indexes])\n",
        "\n",
        "        return (data_batch, target_batch)\n",
        "\n",
        "\n",
        "\n",
        "    # It resets data indexes for shuffling at the end of each epoch\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.data))\n",
        "        if self.shuffle:\n",
        "            if self.seed is not None:\n",
        "                np.random.seed(self.seed)\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "\n",
        "\n",
        "    # It preprocesses tweet data for model input.\n",
        "    def _prepare_data(self):\n",
        "\n",
        "        # Tweets are firstly tokenized, and then padding is applied to reach \"max_len\" length\n",
        "        self.tweet = [word_tokenize(sentence, self.lang) + ['<pad>']*(self.max_len - len(word_tokenize(sentence, self.lang))) for sentence in self.tweet]\n",
        "\n",
        "        # Words are converted to their corresponding indices using `word_to_idx`, and unknown words are replaced with the '<unk>' index.\n",
        "        self.tweet = [[self.word_to_idx[word] if word in self.word_listing else self.word_to_idx[\"<unk>\"] for word in sentence] for sentence in self.tweet]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trainings for English models"
      ],
      "metadata": {
        "id": "8pkgvjp9uf16"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "execution": {
          "iopub.execute_input": "2024-11-27T15:02:51.847482Z",
          "iopub.status.busy": "2024-11-27T15:02:51.846804Z",
          "iopub.status.idle": "2024-11-27T15:14:53.751229Z",
          "shell.execute_reply": "2024-11-27T15:14:53.750358Z",
          "shell.execute_reply.started": "2024-11-27T15:02:51.847448Z"
        },
        "id": "Eck0jLmS4paV",
        "outputId": "67d8f4df-7ab1-4d16-f235-131c56e849da",
        "trusted": true,
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model Baseline_LSTM_42...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "'Baseline_LSTM_42(English)_Baseline_LSTM_42(English)_encoder_embedding_embeddings_momentum' is not a valid scope name. A scope name has to match the following pattern: ^[A-Za-z0-9_.\\\\/>-]*$",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-217574325313>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nTraining model {baseline_LSTM.name}...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mbaseline_LSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf1_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_check\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mGL_baseline_urls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./GloVe/baseline_instances/baseline_{seed}.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_traceback_filtering_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mone_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;34m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             outputs = self.distribute_strategy.run(\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mone_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;34m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The model does not have any trainable weights.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables_are_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/nadam.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             self._momentums.append(\n\u001b[0;32m---> 96\u001b[0;31m                 self.add_variable_from_reference(\n\u001b[0m\u001b[1;32m     97\u001b[0m                     \u001b[0mreference_variable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36madd_variable_from_reference\u001b[0;34m(self, reference_variable, name, initializer)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mcolocate_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         ):\n\u001b[0;32m---> 36\u001b[0;31m             return super().add_variable_from_reference(\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0mreference_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36madd_variable_from_reference\u001b[0;34m(self, reference_variable, name, initializer)\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             )\n\u001b[0;32m--> 227\u001b[0;31m         return self.add_variable(\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreference_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36madd_variable\u001b[0;34m(self, shape, initializer, dtype, aggregation, name)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             variable = backend.Variable(\n\u001b[0m\u001b[1;32m    202\u001b[0m                 \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initializer, shape, dtype, trainable, autocast, aggregation, name)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_with_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36m_initialize_with_initializer\u001b[0;34m(self, initializer)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize_with_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         self._value = tf.Variable(\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'Baseline_LSTM_42(English)_Baseline_LSTM_42(English)_encoder_embedding_embeddings_momentum' is not a valid scope name. A scope name has to match the following pattern: ^[A-Za-z0-9_.\\\\/>-]*$"
          ]
        }
      ],
      "source": [
        "GL_baseline_f1_scores = []\n",
        "GL_baseline_urls = []\n",
        "GL_model_1_f1_scores = []\n",
        "GL_model_1_urls = []\n",
        "\n",
        "for seed in seeds:\n",
        "\n",
        "    # Seed initialization\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Data generation\n",
        "    train_gen = DataGenerator(df_train_T2, word_to_idx_en, word_listing_en, max_len_en, batch_size=batch_size, shuffle=True, seed=seed)\n",
        "    validation_gen = DataGenerator(df_val_T2, word_to_idx_en, word_listing_en, max_len_en, batch_size=1, shuffle=False, seed=seed)\n",
        "\n",
        "\n",
        "\n",
        "    # ----- BASELINE LSTM ----- #\n",
        "    baseline_LSTM = Bidirectional_LSTM(input_dim=max_len_en,\n",
        "                                       output_dim=num_classes,\n",
        "                                       hidden_dim=hidden_dim,\n",
        "                                       vocab_size=vocab_size_en,\n",
        "                                       embedding_matrix=embed_matrix_glove,\n",
        "                                       num_layers=1,\n",
        "                                       name=f\"Baseline_LSTM_{seed}\")\n",
        "    baseline_LSTM.compile(optimizer=Nadam(ema_momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Callbacks definition\n",
        "    f1_call = F1ScoreCallback(validation_gen)\n",
        "    model_check = ModelCheckpoint(f'./GloVe/baseline_instances/baseline_{seed}.keras', monitor='f1_score', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "    # Training\n",
        "    print(f'\\nTraining model {baseline_LSTM.name}...')\n",
        "    baseline_LSTM.fit(train_gen, validation_data=validation_gen, batch_size=batch_size, epochs=epochs, callbacks=[f1_call, model_check], verbose=0)\n",
        "    GL_baseline_urls.append(f'./GloVe/baseline_instances/baseline_{seed}.keras')\n",
        "\n",
        "    # F1 score computation on the validation set\n",
        "    baseline_LSTM = keras.saving.load_model(f'./GloVe/baseline_instances/baseline_{seed}.keras')\n",
        "    pred = baseline_LSTM.predict(validation_gen, verbose=0)\n",
        "    f1 = f1_score(np.argmax(pred, axis=-1), df_val_T2['hard_labels_task1'].to_list())\n",
        "    GL_baseline_f1_scores.append(f1)\n",
        "    print('   [COMPLETE]')\n",
        "\n",
        "\n",
        "\n",
        "    # ----- MODEL 1 LSTM ----- #\n",
        "    model_1_LSTM = Bidirectional_LSTM(input_dim=max_len_en,\n",
        "                                     output_dim=num_classes,\n",
        "                                     hidden_dim=hidden_dim,\n",
        "                                     vocab_size=vocab_size_en,\n",
        "                                     embedding_matrix=embed_matrix_glove,\n",
        "                                     num_layers=2,\n",
        "                                     name=f\"Model_1_LSTM_{seed}\")\n",
        "    model_1_LSTM.compile(optimizer=Nadam(ema_momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Callbacks definition\n",
        "    f1_call = F1ScoreCallback(validation_gen)\n",
        "    model_check = ModelCheckpoint(f'./GloVe/model_1_instances/model_1_{seed}.keras', monitor='f1_score', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "    # Training\n",
        "    print(f'\\nTraining model {model_1_LSTM.name}...')\n",
        "    model_1_LSTM.fit(train_gen, validation_data=validation_gen, batch_size=batch_size, epochs=epochs, callbacks=[f1_call, model_check], verbose=0)\n",
        "    GL_model_1_urls.append(f'./GloVe/model_1_instances/model_1_{seed}.keras')\n",
        "\n",
        "    # F1 score computation on the validation set\n",
        "    model_1_LSTM = keras.saving.load_model(f'./GloVe/model_1_instances/model_1_{seed}.keras')\n",
        "    pred = model_1_LSTM.predict(validation_gen, verbose=0)\n",
        "    f1 = f1_score(np.argmax(pred, axis=-1), df_val_T2['hard_labels_task1'].to_list())\n",
        "    GL_model_1_f1_scores.append(f1)\n",
        "    print('   [COMPLETE]')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trainings for Spanish models"
      ],
      "metadata": {
        "id": "12XjtMDLsGlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################\n",
        "# -- SPANISH TRAININGS HERE -- #\n",
        "################################"
      ],
      "metadata": {
        "id": "8s8yG45KsM87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dakKLGttEMW5"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_X2jOMUDrv7"
      },
      "source": [
        "### Baseline performances evaluation (English)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T15:15:11.425426Z",
          "iopub.status.busy": "2024-11-27T15:15:11.424544Z",
          "iopub.status.idle": "2024-11-27T15:15:12.893719Z",
          "shell.execute_reply": "2024-11-27T15:15:12.892870Z",
          "shell.execute_reply.started": "2024-11-27T15:15:11.425377Z"
        },
        "id": "DM5_kcd09aIr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "average = np.average(GL_baseline_f1_scores)\n",
        "std = np.std(GL_baseline_f1_scores)\n",
        "\n",
        "idx_base = np.argmax(GL_baseline_f1_scores)\n",
        "best_f1_base = GL_baseline_f1_scores[idx_base]\n",
        "best_url_base = GL_baseline_urls[idx_base]\n",
        "best_seed_base = seeds[idx_base]\n",
        "\n",
        "print(\"Baseline LSTM average performances on the validation set\")\n",
        "print(\"  - Mean:\", average)\n",
        "print(\"  - Standard deviation:\", std)\n",
        "\n",
        "\n",
        "# Test set performances\n",
        "baseline_LSTM = keras.saving.load_model(best_url_base)\n",
        "test_gen = DataGenerator(df_test_T2, word_to_idx_en, word_listing_en, max_len_en, batch_size=1, shuffle=False, seed=best_seed_base)\n",
        "pred_base = baseline_LSTM.predict(test_gen, verbose=0)\n",
        "f1_base = f1_score(np.argmax(pred_base, axis=-1), df_test_T2['hard_labels_task1'].to_list(), average='macro')\n",
        "\n",
        "print('\\nBaseline LSTM test performances')\n",
        "print('  - Seed:', best_seed_base)\n",
        "print('  - F1 score =', f1_base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdJW0mUTD3-l"
      },
      "source": [
        "### Model 1 performances evaluation (English)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T15:15:27.227329Z",
          "iopub.status.busy": "2024-11-27T15:15:27.226951Z",
          "iopub.status.idle": "2024-11-27T15:15:29.032154Z",
          "shell.execute_reply": "2024-11-27T15:15:29.031215Z",
          "shell.execute_reply.started": "2024-11-27T15:15:27.227298Z"
        },
        "id": "BjDsuXz69lIy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "average = np.average(GL_model_1_f1_scores)\n",
        "std = np.std(GL_model_1_f1_scores)\n",
        "\n",
        "idx_model_1 = np.argmax(GL_model_1_f1_scores)\n",
        "best_f1_model_1 = GL_model_1_f1_scores[idx_model_1]\n",
        "best_url_model_1 = GL_model_1_urls[idx_model_1]\n",
        "best_seed_model_1 = seeds[idx_model_1]\n",
        "\n",
        "print(\"Model 1 LSTM average performances on the validation set\")\n",
        "print(\"  - Mean:\", average)\n",
        "print(\"  - Standard deviation:\", std)\n",
        "\n",
        "\n",
        "# Test set performances\n",
        "model_1_LSTM = keras.saving.load_model(best_url_model_1)\n",
        "test_gen = DataGenerator(df_test_T2, word_to_idx_en, word_listing_en, max_len_en, language='english', batch_size=1, shuffle=False, seed=best_seed_model_1)\n",
        "pred_model_1 = model_1_LSTM.predict(test_gen, verbose=0)\n",
        "f1_model_1 = f1_score(np.argmax(pred_model_1, axis=-1), df_test_T2['hard_labels_task1'].to_list(), average='macro')\n",
        "\n",
        "print('\\nModel 1 LSTM test performances')\n",
        "print('  - Seed:', best_seed_base)\n",
        "print('  - F1 score =', f1_base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSr90uOYD7yG"
      },
      "source": [
        "### Best model evaluation (English)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T15:15:42.808536Z",
          "iopub.status.busy": "2024-11-27T15:15:42.808200Z",
          "iopub.status.idle": "2024-11-27T15:15:44.060424Z",
          "shell.execute_reply": "2024-11-27T15:15:44.059438Z",
          "shell.execute_reply.started": "2024-11-27T15:15:42.808506Z"
        },
        "id": "AAw4qw_8_y00",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "if best_f1_base > best_f1_model_1:\n",
        "    best_LSTM = baseline_LSTM\n",
        "    best_f1_val = best_f1_base\n",
        "    best_seed = best_seed_base\n",
        "else:\n",
        "    best_LSTM = model_1_LSTM\n",
        "    best_f1_val = best_f1_model_1\n",
        "    best_seed = best_seed_model_1\n",
        "\n",
        "\n",
        "test_gen = DataGenerator(df_test_T2, word_to_idx_en, word_listing_en, max_len_en, batch_size=1, shuffle=False, seed=best_seed)\n",
        "pred_LSTM = best_LSTM.predict(test_gen, verbose=0)\n",
        "f1_LSTM = f1_score(np.argmax(pred_LSTM, axis=-1), df_test_T2['hard_labels_task1'].to_list(), average='macro')\n",
        "\n",
        "print('\\nBest Model (GloVe):', best_LSTM.name)\n",
        "print('  - Seed:', best_seed)\n",
        "print('  - Val F1 score =', best_f1_val)\n",
        "print('  - F1 score =', f1_LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YW3NXkYCDdGx"
      },
      "outputs": [],
      "source": [
        "df_test_T5 = df_test_T2.copy()\n",
        "df_test_T5['predictions'] = np.argmax(pred_LSTM, axis=-1)\n",
        "df_test_T5.to_csv(\"df_test_LSTM.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best model evaluation (Spanish)"
      ],
      "metadata": {
        "id": "w66AxAn40ZDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "# -- SPANISH EVALUATION -- #\n",
        "############################"
      ],
      "metadata": {
        "id": "VajBc_rRtKbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSy9sPwYHUoD"
      },
      "source": [
        "# [Task 6 - 1.0 points] Transformers\n",
        "\n",
        "\n",
        "\n",
        "In this section, you will use a transformer model specifically trained for hate speech detection, namely [Twitter-roBERTa-base for Hate Speech Detection](https://huggingface.co/cardiffnlp/twitter-roberta-base-hate).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "sis25UdYIMER",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "### Relevant Material\n",
        "\n",
        "- Tutorial 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_N_UNitNIMER",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "### Instructions\n",
        "\n",
        "1. **Load the Tokenizer and Model**\n",
        "\n",
        "\n",
        "\n",
        "2. **Preprocess the Dataset**:\n",
        "\n",
        "   You will need to preprocess your dataset to prepare it for input into the model. Tokenize your text data using the appropriate tokenizer and ensure it is formatted correctly.\n",
        "\n",
        "\n",
        "\n",
        "   **Note**: You have to use the plain text of the dataset and not the version that you tokenized before, as you need to tokenize the cleaned text obtained after the initial cleaning process.\n",
        "\n",
        "\n",
        "\n",
        "3. **Train the Model**:\n",
        "\n",
        "   Use the `Trainer` to train the model on your training data.\n",
        "\n",
        "\n",
        "\n",
        "4. **Evaluate the Model on the Test Set** using F1-macro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1lCmsfy8VLF"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb9bU74QP0VZ"
      },
      "source": [
        "1. **Load the Tokenizer and Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T17:38:57.504718Z",
          "iopub.status.busy": "2024-11-27T17:38:57.503949Z",
          "iopub.status.idle": "2024-11-27T17:38:58.042057Z",
          "shell.execute_reply": "2024-11-27T17:38:58.041206Z",
          "shell.execute_reply.started": "2024-11-27T17:38:57.504671Z"
        },
        "id": "8wxcgSFbPwdt",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_card_en = 'cardiffnlp/twitter-roberta-base-hate'\n",
        "tokenizer_en = AutoTokenizer.from_pretrained(model_card_en)\n",
        "model_en = AutoModelForSequenceClassification.from_pretrained(model_card_en,\n",
        "                                                              num_labels=num_classes,\n",
        "                                                              id2label={0: 'NEG', 1: 'POS'},\n",
        "                                                              label2id={'NEG': 0, 'POS': 1})\n",
        "data_collator_en = DataCollatorWithPadding(tokenizer=tokenizer_en)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_card_es = 'cardiffnlp/twitter-xlm-roberta-base-hate-spanish'\n",
        "tokenizer_es = AutoTokenizer.from_pretrained(model_card_es)\n",
        "model_es = AutoModelForSequenceClassification.from_pretrained(model_card_es,\n",
        "                                                              num_labels=num_classes,\n",
        "                                                              id2label={0: 'NEG', 1: 'POS'},\n",
        "                                                              label2id={'NEG': 0, 'POS': 1})\n",
        "data_collator_es = DataCollatorWithPadding(tokenizer=tokenizer_es)"
      ],
      "metadata": {
        "id": "XQ1Zw-yy_arV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zyq1P_jP3r2"
      },
      "source": [
        "2. **Preprocess the Dataset**:\n",
        "\n",
        "   You will need to preprocess your dataset to prepare it for input into the model. Tokenize your text data using the appropriate tokenizer and ensure it is formatted correctly.\n",
        "\n",
        "\n",
        "\n",
        "   **Note**: You have to use the plain text of the dataset and not the version that you tokenized before, as you need to tokenize the cleaned text obtained after the initial cleaning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T17:38:58.479502Z",
          "iopub.status.busy": "2024-11-27T17:38:58.479142Z",
          "iopub.status.idle": "2024-11-27T17:38:58.873932Z",
          "shell.execute_reply": "2024-11-27T17:38:58.873114Z",
          "shell.execute_reply.started": "2024-11-27T17:38:58.479472Z"
        },
        "id": "ZtvMZzVSP9_H",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "f1eb5d9b27e94ce6a086f87f6b2ed2a5",
            "78c34feee79a46debe1cb9b04a3864e9",
            "8087c307a15f4ebabbb415058ae08cdc",
            "9f5aacc2dd8f412eae8b2a7716972bb0",
            "281b84aa936a4381925edc4fadcf36ef",
            "2fd07001d9e144cab6c7f81edf8194f3",
            "cedf030ac38a4460aae7ca6c4590daec",
            "56e42697437e4a4ab34df9cfa69fe339",
            "a71c9431040a48938fc890f2ae22a322",
            "0913e0fafc1c48eeb150143745869a7f",
            "0538b2f513a14baca091a6a17631b08d",
            "470e9585e925493e92e7d2e64d969a98",
            "ffdfd24abe7f49dda035bc86efd7b71b",
            "3342b67848ed475f9115a3b7e4b97ad3",
            "a9613759bdc1435ea43526d9df3a3a60",
            "a9517504813a4230a1c27c00ff717b8c",
            "08247ab3f1954f9298df9f97f0d452a6",
            "f83249d876af47c9bb4b39ed0485edd9",
            "baa0e90900c34302b03a8a23dc2aa5f2",
            "58df9f10b6f0466f89841384a8e74950",
            "4dec5d8b223d4062b223011264230e6a",
            "36137c437cbc4ce48c6e128d0cb11231",
            "6f8d6fbe2467427a8f71279c8145961d",
            "10d2f7ab833e42639fa5c3cc7b31872c",
            "34d2238a8c994a2ab465f97cb0081f96",
            "77eaab8a1b074355842b9c3d357ff937",
            "004edb525df3421ababeddeb6d445b08",
            "f1215cca066c4d2888b68597fe9eb324",
            "db8e4f36e7bd4893b70a52ebeae87050",
            "8514d15c821b43a6978b5d836905dee3",
            "b140766256b948bf9eeac9f35e7c5133",
            "edd304dd396341b987b61c13e1e0b8d6",
            "ea222f925689483d9eab61462202a9dd",
            "15f91948c7bf48d4bb457e5b731054c7",
            "faea7d13c37f432aa3013ad0f86f748b",
            "e214504b66fa47c6b33d31fedda5e80c",
            "b5567d5ff43d44418d945ff6e8acf5db",
            "277c529fccf3418e84e7a9d7041f72b6",
            "dd2b912fb34642da9ef7cefe237f9afb",
            "e06aebebc2c641d4a116d141e7d0d2e2",
            "c2321710873946d7bd476263659630f4",
            "9df702cd52524ea5a04b61804c1e2a2a",
            "2628db3dfbbe4b6ba52c6e542a8a0abe",
            "53a51333c9014034860186133a882852",
            "5211205c6ad24e549a0fbe0b999a0a45",
            "357397d4e0df455f9b7e9037dbe8a695",
            "84cc9749187543f2a44fe415edede768",
            "a624967a95f6447d87ced0216e6b34a5",
            "8456f7edc7ff4fbda56325bdb93eab56",
            "c3d7dd35eb074b49abaaf68c75e783d6",
            "509caec5f0c64b2eaabc404bc415d4f9",
            "2af38a514812494984c53ca7c85332f6",
            "06343bda44174b5abe7c77e595ac91e6",
            "c28d74713ebe44c4aa7e320e64aa4fc8",
            "672881480bc543bda7b137d842cbdd90"
          ]
        },
        "outputId": "eb56457e-ecb9-4853-efe9-460f142d3575"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2870 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1eb5d9b27e94ce6a086f87f6b2ed2a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/158 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "470e9585e925493e92e7d2e64d969a98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/286 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f8d6fbe2467427a8f71279c8145961d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3194 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15f91948c7bf48d4bb457e5b731054c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/490 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5211205c6ad24e549a0fbe0b999a0a45"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# df_train_T2 -> It contains the english tweets after the cleaning step of Task 2\n",
        "# df_train_es -> It contains the spanish tweets after the cleaning step of Task 2\n",
        "\n",
        "train_data_en = Dataset.from_pandas(df_train_T2)\n",
        "val_data_en = Dataset.from_pandas(df_val_T2)\n",
        "test_data_en = Dataset.from_pandas(df_test_T2)\n",
        "\n",
        "train_data_es = Dataset.from_pandas(df_train_clean_es)\n",
        "val_data_es = Dataset.from_pandas(df_val_clean_es)\n",
        "\n",
        "\n",
        "\n",
        "# Data are preprocessed through a tokenizer\n",
        "def preprocess_text_en(texts):\n",
        "    return tokenizer_en(texts['tweet'], truncation=True)\n",
        "\n",
        "def preprocess_text_es(texts):\n",
        "    return tokenizer_es(texts['tweet'], truncation=True)\n",
        "\n",
        "# This applies the preprocessing function to training and test data in batches (batched = True)\n",
        "train_data_en = train_data_en.map(preprocess_text_en, batched=True)\n",
        "val_data_en = val_data_en.map(preprocess_text_en, batched=True)\n",
        "test_data_en = test_data_en.map(preprocess_text_en, batched=True)\n",
        "\n",
        "train_data_es = train_data_es.map(preprocess_text_es, batched=True)\n",
        "val_data_es = val_data_es.map(preprocess_text_es, batched=True)\n",
        "\n",
        "\n",
        "\n",
        "train_data_en = train_data_en.rename_column('hard_labels_task1', 'label')\n",
        "val_data_en = val_data_en.rename_column('hard_labels_task1', 'label')\n",
        "test_data_en = test_data_en.rename_column('hard_labels_task1', 'label')\n",
        "\n",
        "train_data_es = train_data_es.rename_column('hard_labels_task1', 'label')\n",
        "val_data_es = val_data_es.rename_column('hard_labels_task1', 'label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T17:39:00.613663Z",
          "iopub.status.busy": "2024-11-27T17:39:00.613276Z",
          "iopub.status.idle": "2024-11-27T17:39:01.152879Z",
          "shell.execute_reply": "2024-11-27T17:39:01.152264Z",
          "shell.execute_reply.started": "2024-11-27T17:39:00.613631Z"
        },
        "id": "LMi57cWRQD6b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "acc_metric = evaluate.load('accuracy')\n",
        "\n",
        "# This function computes accuracy and F1 metrics\n",
        "def compute_metrics(output_info):\n",
        "\n",
        "    predictions, labels = output_info\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    f1 = f1_score(predictions, labels, average=\"macro\")\n",
        "    acc = acc_metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "    return {\"f1\": f1,**acc}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T17:39:02.192848Z",
          "iopub.status.busy": "2024-11-27T17:39:02.192558Z",
          "iopub.status.idle": "2024-11-27T17:39:02.227865Z",
          "shell.execute_reply": "2024-11-27T17:39:02.226797Z",
          "shell.execute_reply.started": "2024-11-27T17:39:02.192824Z"
        },
        "id": "xEWR8hl8QHha",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "\n",
        "    output_dir=\"test_dir\",\n",
        "    logging_first_step=True,\n",
        "    learning_rate=5e-6,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    adam_epsilon=1e-8,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    report_to='none',\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### English dataset training"
      ],
      "metadata": {
        "id": "n_L6SP0JAdOV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T17:39:03.961156Z",
          "iopub.status.busy": "2024-11-27T17:39:03.960827Z",
          "iopub.status.idle": "2024-11-27T17:39:04.154600Z",
          "shell.execute_reply": "2024-11-27T17:39:04.153902Z",
          "shell.execute_reply.started": "2024-11-27T17:39:03.961127Z"
        },
        "id": "LzG2-JCHQJC6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "trainer_en = Trainer(\n",
        "\n",
        "    model=model_en,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data_en,\n",
        "    eval_dataset=val_data_en,\n",
        "    processing_class=tokenizer_en,\n",
        "    data_collator=data_collator_en,\n",
        "    compute_metrics=compute_metrics,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T17:39:09.009059Z",
          "iopub.status.busy": "2024-11-27T17:39:09.008220Z",
          "iopub.status.idle": "2024-11-27T17:43:06.061254Z",
          "shell.execute_reply": "2024-11-27T17:43:06.060419Z",
          "shell.execute_reply.started": "2024-11-27T17:39:09.009024Z"
        },
        "id": "Sgw9H-iZQKcD",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "16b6f84e-4f37-40be-f635-41bc1d6b187f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1800/1800 08:28, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.603000</td>\n",
              "      <td>0.417969</td>\n",
              "      <td>0.835437</td>\n",
              "      <td>0.841772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.603000</td>\n",
              "      <td>0.389795</td>\n",
              "      <td>0.829289</td>\n",
              "      <td>0.835443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.389900</td>\n",
              "      <td>0.411744</td>\n",
              "      <td>0.849355</td>\n",
              "      <td>0.854430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.389900</td>\n",
              "      <td>0.465224</td>\n",
              "      <td>0.828404</td>\n",
              "      <td>0.835443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.389900</td>\n",
              "      <td>0.540898</td>\n",
              "      <td>0.819199</td>\n",
              "      <td>0.829114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.257200</td>\n",
              "      <td>0.565269</td>\n",
              "      <td>0.821319</td>\n",
              "      <td>0.829114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.257200</td>\n",
              "      <td>0.683183</td>\n",
              "      <td>0.824174</td>\n",
              "      <td>0.835443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.257200</td>\n",
              "      <td>0.721598</td>\n",
              "      <td>0.825340</td>\n",
              "      <td>0.835443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.178800</td>\n",
              "      <td>0.704318</td>\n",
              "      <td>0.833607</td>\n",
              "      <td>0.841772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.178800</td>\n",
              "      <td>0.719538</td>\n",
              "      <td>0.839784</td>\n",
              "      <td>0.848101</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1800, training_loss=0.2536724606818623, metrics={'train_runtime': 508.182, 'train_samples_per_second': 56.476, 'train_steps_per_second': 3.542, 'total_flos': 542326357307640.0, 'train_loss': 0.2536724606818623, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "trainer_en.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpHXFJGnQOrw"
      },
      "source": [
        "4. **Evaluate the Model on the Test Set** using F1-macro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T17:43:06.063783Z",
          "iopub.status.busy": "2024-11-27T17:43:06.062953Z",
          "iopub.status.idle": "2024-11-27T17:43:07.344989Z",
          "shell.execute_reply": "2024-11-27T17:43:07.344009Z",
          "shell.execute_reply.started": "2024-11-27T17:43:06.063753Z"
        },
        "id": "Hvpb85g7QMmi",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "86c527f0-e626-4df0-cc40-2f9efe000b6a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metrics (Val):\n",
            " {'f1': 0.8493553869750861, 'accuracy': 0.8544303797468354} \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metrics (Test):\n",
            " {'f1': 0.8132584297347575, 'accuracy': 0.8146853146853147}\n"
          ]
        }
      ],
      "source": [
        "val_prediction_info = trainer_en.predict(val_data_en)\n",
        "val_metrics_en = compute_metrics([val_prediction_info.predictions, val_prediction_info.label_ids])\n",
        "print(\"Evaluation metrics (Val):\\n\", val_metrics_en, '\\n')\n",
        "\n",
        "test_prediction_info = trainer_en.predict(test_data_en)\n",
        "test_metrics_en = compute_metrics([test_prediction_info.predictions, test_prediction_info.label_ids])\n",
        "print(\"Evaluation metrics (Test):\\n\", test_metrics_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk1m3GsGDw9M"
      },
      "outputs": [],
      "source": [
        "df_test_T6 = df_test_T2.copy()\n",
        "df_test_T6['predictions'] = np.argmax(test_prediction_info.predictions, axis=-1)\n",
        "df_test_T6.to_csv(\"df_test_Transformer.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Spanish dataset training"
      ],
      "metadata": {
        "id": "5WM9DTXqAyks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_es = Trainer(\n",
        "\n",
        "    model=model_es,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data_es,\n",
        "    eval_dataset=val_data_es,\n",
        "    processing_class=tokenizer_es,\n",
        "    data_collator=data_collator_es,\n",
        "    compute_metrics=compute_metrics,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "jY4VnMMfA2Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_es.train()"
      ],
      "metadata": {
        "id": "e3ZUqIK4BD8K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "e444dba6-5ad9-4946-ecec-49858184e099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 15:51, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.356300</td>\n",
              "      <td>0.445474</td>\n",
              "      <td>0.800681</td>\n",
              "      <td>0.804082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.356300</td>\n",
              "      <td>0.453890</td>\n",
              "      <td>0.803070</td>\n",
              "      <td>0.806122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.416600</td>\n",
              "      <td>0.534807</td>\n",
              "      <td>0.804886</td>\n",
              "      <td>0.806122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.416600</td>\n",
              "      <td>0.589545</td>\n",
              "      <td>0.804322</td>\n",
              "      <td>0.806122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.217200</td>\n",
              "      <td>0.660414</td>\n",
              "      <td>0.816020</td>\n",
              "      <td>0.816327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.217200</td>\n",
              "      <td>0.754679</td>\n",
              "      <td>0.814006</td>\n",
              "      <td>0.814286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.217200</td>\n",
              "      <td>0.877563</td>\n",
              "      <td>0.821538</td>\n",
              "      <td>0.822449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.103900</td>\n",
              "      <td>0.965715</td>\n",
              "      <td>0.813801</td>\n",
              "      <td>0.814286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.103900</td>\n",
              "      <td>1.045527</td>\n",
              "      <td>0.809709</td>\n",
              "      <td>0.810204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.077000</td>\n",
              "      <td>1.068711</td>\n",
              "      <td>0.817637</td>\n",
              "      <td>0.818367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2000, training_loss=0.20415427029132843, metrics={'train_runtime': 952.1618, 'train_samples_per_second': 33.545, 'train_steps_per_second': 2.1, 'total_flos': 700558879335000.0, 'train_loss': 0.20415427029132843, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_prediction_info = trainer_es.predict(val_data_es)\n",
        "val_metrics_es = compute_metrics([val_prediction_info.predictions, val_prediction_info.label_ids])\n",
        "print(\"Spanish model evaluation metrics (Val):\\n\", val_metrics_es)"
      ],
      "metadata": {
        "id": "89x7Ah1vC4y9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4a470483-618b-4592-fd21-a28f76a8225c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spanish model evaluation metrics (Val):\n",
            " {'f1': 0.8215384615384616, 'accuracy': 0.8224489795918367}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gtiG2mAL3HM"
      },
      "source": [
        "# [Task 7 - 0.5 points] Error Analysis\n",
        "\n",
        "\n",
        "\n",
        "### Instructions\n",
        "\n",
        "\n",
        "\n",
        "After evaluating the model, perform a brief error analysis:\n",
        "\n",
        "\n",
        "\n",
        " - Review the results and identify common errors.\n",
        "\n",
        "\n",
        "\n",
        " - Summarize your findings regarding the errors and their impact on performance (e.g. but not limited to Out-of-Vocabulary (OOV) words, data imbalance, and performance differences between the custom model and the transformer...)\n",
        "\n",
        " - Suggest possible solutions to address the identified errors.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em949NKO8VLG"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0-vG0xuWyY9"
      },
      "source": [
        "## Class Imbalance\n",
        "One key challenge in this task is the **class imbalance** present in the training set. The majority of tweets are labeled as _\"non-sexist\" (0)_, which introduces a bias in the inference phase. This bias skews the model's predictions toward the majority class, as demonstrated by the class distributions shown below. Such imbalance can affect the model's ability to correctly identify the minority class _\"sexist\" (1)_, which is critical in this application.\n",
        "\n",
        "The imbalance is further highlighted by differences in class distributions between the training and test datasets. These disparities can cause the model to generalize poorly, as it encounters a different data distribution during evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fnsOs5DXhqm"
      },
      "source": [
        "- **TRAINING SET**: labels' distribution of _sexist_ (**1**) and _non-sexist_ (**0**) tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T17:30:15.339528Z",
          "iopub.status.busy": "2024-11-27T17:30:15.339137Z",
          "iopub.status.idle": "2024-11-27T17:30:15.346490Z",
          "shell.execute_reply": "2024-11-27T17:30:15.345630Z",
          "shell.execute_reply.started": "2024-11-27T17:30:15.339492Z"
        },
        "id": "sH83p9U0scmB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_train_T2['hard_labels_task1'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v3apwZoW8ws"
      },
      "source": [
        "- **TEST SET**: labels' distribution of _sexist_ (**1**) and _non-sexist_ (**0**) tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T17:30:14.512793Z",
          "iopub.status.busy": "2024-11-27T17:30:14.511895Z",
          "iopub.status.idle": "2024-11-27T17:30:14.519735Z",
          "shell.execute_reply": "2024-11-27T17:30:14.518900Z",
          "shell.execute_reply.started": "2024-11-27T17:30:14.512758Z"
        },
        "id": "ulkllHEZscmA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_test_T2['hard_labels_task1'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9QBn5gkX9-F"
      },
      "source": [
        "## Labeling evaluation\n",
        "To better understand the factors influencing the performance of the model, the following information have been analysed and grouped:\n",
        "\n",
        "- **Tweet Length**\n",
        "- **Number of Unknown Tokens**\n",
        "- **Number of Out-Of-Vocabulary (OOV) Terms**\n",
        "\n",
        "The related values are compared between _correct_ and _wrong predictions_ to assess their impact on the labeling accuracy. The analysis is conducted on both the LSTM best model and the Transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T17:30:09.278902Z",
          "iopub.status.busy": "2024-11-27T17:30:09.278273Z",
          "iopub.status.idle": "2024-11-27T17:30:09.565989Z",
          "shell.execute_reply": "2024-11-27T17:30:09.565323Z",
          "shell.execute_reply.started": "2024-11-27T17:30:09.278869Z"
        },
        "id": "x__wIcuZS15I",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_err_LSTM = pd.read_csv(\"df_test_LSTM.csv\", index_col=\"id_EXIST\")\n",
        "df_err_LSTM['tweet_length'] = df_err_LSTM['tweet'].apply(lambda x: len(word_tokenize(x)))\n",
        "df_err_LSTM[\"unknowns_number\"] = df_err_LSTM['tweet'].apply(lambda x: len([word for word in word_tokenize(x) if word not in word_listing]))\n",
        "df_err_LSTM[\"oov_terms_number\"] = df_err_LSTM['tweet'].apply(lambda x: len([word for word in word_tokenize(x) if word in oov_terms]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T17:30:25.385095Z",
          "iopub.status.busy": "2024-11-27T17:30:25.384700Z",
          "iopub.status.idle": "2024-11-27T17:30:25.391057Z",
          "shell.execute_reply": "2024-11-27T17:30:25.390176Z",
          "shell.execute_reply.started": "2024-11-27T17:30:25.385061Z"
        },
        "id": "sS6WDIfEYkI7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_correct_LSTM = df_err_LSTM[df_err_LSTM['hard_labels_task1'] == df_err_LSTM['predictions']]\n",
        "df_errors_LSTM = df_err_LSTM[df_err_LSTM['hard_labels_task1'] != df_err_LSTM['predictions']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yK495t1OAk4"
      },
      "outputs": [],
      "source": [
        "df_correct_LSTM.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJmgAlMeOU3T"
      },
      "outputs": [],
      "source": [
        "df_errors_LSTM.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94xjlA1GngcW"
      },
      "outputs": [],
      "source": [
        "len_correct = df_correct_LSTM.shape[0]\n",
        "len_errors = df_errors_LSTM.shape[0]\n",
        "\n",
        "fig, axes = plt.subplots(3, 1, figsize=(8, 12))\n",
        "axes[0].hist(df_correct_LSTM['tweet_length'], bins=range(max_len), label=f'correct - mean: {np.mean(df_correct_LSTM.tweet_length):.2f}')\n",
        "axes[0].hist(df_errors_LSTM['tweet_length'], bins=range(max_len), label=f'errors - mean: {np.mean(df_errors_LSTM.tweet_length):.2f}')\n",
        "axes[0].set_title('Tweet length')\n",
        "axes[0].legend()\n",
        "\n",
        "bin_n = max(len(df_correct_LSTM['unknowns_number'].unique()), len(df_errors_LSTM['unknowns_number'].unique()))\n",
        "axes[1].hist(df_correct_LSTM['unknowns_number'], bins=range(bin_n), label=f'correct - mean: {np.mean(df_correct_LSTM.unknowns_number):.2f}')\n",
        "axes[1].hist(df_errors_LSTM['unknowns_number'], bins=range(bin_n), label=f'errors - mean: {np.mean(df_errors_LSTM.unknowns_number):.2f}')\n",
        "axes[1].set_title('Unknowns number')\n",
        "axes[1].legend()\n",
        "\n",
        "bin_n = max(len(df_correct_LSTM['oov_terms_number'].unique()), len(df_errors_LSTM['oov_terms_number'].unique()))\n",
        "axes[2].hist(df_correct_LSTM['oov_terms_number'], bins=range(bin_n), label=f'correct - mean: {np.mean(df_correct_LSTM.oov_terms_number):.2f}')\n",
        "axes[2].hist(df_errors_LSTM['oov_terms_number'], bins=range(bin_n), label=f'errors - mean: {np.mean(df_errors_LSTM.oov_terms_number):.2f}')\n",
        "axes[2].set_title('OOV terms number')\n",
        "axes[2].legend()\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FnsMei-Zv24"
      },
      "source": [
        "What can be inferred for the LSTM are the following statements:\n",
        "\n",
        "- **The LSTM classifier appears to handle Unknown and OOV Terms relatively well**, as these factors don't drastically affect the model performances in general. On the other side, **the Tweet Lenght seems to play a bigger role in the differentiation of correct and incorrect predictions.**\n",
        "\n",
        "- Tweets that are classified correctly tend to have slightly longer average lengths (mean: 14.95) compared to incorrectly classified tweets (mean: 13.06). In addition, looking at the distributions, there are more instances of shorter tweets in the error distribution, suggesting that shorter tweets might be harder for the classifier to handle. <br>\n",
        "One reason might be that **the model relies on contextual information present in longer tweets for correct predictions, in contrast to shorter ones, which may lack sufficient information, leading to errors**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKlrsfMTaBzf"
      },
      "outputs": [],
      "source": [
        "df_err_transformer = pd.read_csv(\"df_test_Transformer.csv\", index_col=\"id_EXIST\")\n",
        "df_err_transformer['tweet_length'] = df_err_transformer['tweet'].apply(lambda x: len(word_tokenize(x)))\n",
        "df_err_transformer[\"unknowns_number\"] = df_err_transformer['tweet'].apply(lambda x: len([word for word in word_tokenize(x) if word not in word_listing]))\n",
        "df_err_transformer[\"oov_terms_number\"] = df_err_transformer['tweet'].apply(lambda x: len([word for word in word_tokenize(x) if word in oov_terms]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5sicjoIbiB7"
      },
      "outputs": [],
      "source": [
        "df_correct_transformer = df_err_transformer[df_err_transformer['hard_labels_task1'] == df_err_transformer['predictions']]\n",
        "df_errors_transformer = df_err_transformer[df_err_transformer['hard_labels_task1'] != df_err_transformer['predictions']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mY02ViPsbi1V"
      },
      "outputs": [],
      "source": [
        "df_correct_transformer.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx2-JobPbnqi"
      },
      "outputs": [],
      "source": [
        "df_errors_transformer.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meRjjoJKbrih"
      },
      "outputs": [],
      "source": [
        "len_correct = df_correct_transformer.shape[0]\n",
        "len_errors = df_errors_transformer.shape[0]\n",
        "\n",
        "fig, axes = plt.subplots(3, 1, figsize=(8, 12))\n",
        "axes[0].hist(df_correct_transformer['tweet_length'], bins=range(max_len), label=f'correct - mean: {np.mean(df_correct_transformer.tweet_length):.2f}')\n",
        "axes[0].hist(df_errors_transformer['tweet_length'], bins=range(max_len), label=f'errors - mean: {np.mean(df_errors_transformer.tweet_length):.2f}')\n",
        "axes[0].set_title('Tweet length')\n",
        "axes[0].legend()\n",
        "\n",
        "bin_n = max(len(df_correct_transformer['unknowns_number'].unique()), len(df_errors_transformer['unknowns_number'].unique()))\n",
        "axes[1].hist(df_correct_transformer['unknowns_number'], bins=range(bin_n), label=f'correct - mean: {np.mean(df_correct_transformer.unknowns_number):.2f}')\n",
        "axes[1].hist(df_errors_transformer['unknowns_number'], bins=range(bin_n), label=f'errors - mean: {np.mean(df_errors_transformer.unknowns_number):.2f}')\n",
        "axes[1].set_title('Unknowns number')\n",
        "axes[1].legend()\n",
        "\n",
        "bin_n = max(len(df_correct_transformer['oov_terms_number'].unique()), len(df_errors_transformer['oov_terms_number'].unique()))\n",
        "axes[2].hist(df_correct_transformer['oov_terms_number'], bins=range(bin_n), label=f'correct - mean: {np.mean(df_correct_transformer.oov_terms_number):.2f}')\n",
        "axes[2].hist(df_errors_transformer['oov_terms_number'], bins=range(bin_n), label=f'errors - mean: {np.mean(df_errors_transformer.oov_terms_number):.2f}')\n",
        "axes[2].set_title('OOV terms number')\n",
        "axes[2].legend()\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80kgZUdreS0g"
      },
      "source": [
        "The analysis for the Transformer seems to be quite the same of the LSTM, for a model that suffers from the same problem as before on the shorter tweets. However, the performances are generally better, assessing that **the attention mechanism provides better generalisation properties for all the lenghts**, mitigating the previous problem. It can also be noticed by the fact that even if the f1 score for the Transformer with respect to the LSTM on the validation set is just a bit higher, on the test set the RoBERTa architecture shows a considerable improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnTVLqXEoCQf"
      },
      "source": [
        "## Word Frequency Analysis\n",
        "\n",
        "The aim this section is to provide a specific view of words occurrences in the tweets. In general, **_Word Frequency Analysis_** is about counting how often each word appears in a given collection of text data in order to identify keywords, common themes and anomalies.\n",
        "\n",
        "In this case, the analysis is conducted by taking into account the most frequent words in the dataset for all the examples predicted as 1 (sexist) and 0 (not sexist). A comparison between the most frequent words in both classes is provided, with a focus on the wrong classified samples, in order to dectect eventual similarities. This has helped to gain more valuable insights on the textual information and structure of the dataset. The objective is to highlight if there is a predominance of words that drives the predictions towards a certain class label, rather than the other.\n",
        "\n",
        "The same type of analysis has been carried out for both the LSTM and the Transformer, starting with the best performing model, with the following results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UR64EcWdtC7"
      },
      "source": [
        "### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy1R1gL2j26x"
      },
      "outputs": [],
      "source": [
        "df_err_transformer[df_err_transformer[\"predictions\"] == 1][\"tweet\"].str.split().explode().value_counts(normalize=True).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEXZ2EsQmR2C"
      },
      "outputs": [],
      "source": [
        "df_err_transformer[df_err_transformer[\"predictions\"] == 0][\"tweet\"].str.split().explode().value_counts(normalize=True).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSGdPm0FmuXx"
      },
      "outputs": [],
      "source": [
        "df_errors_transformer[\"tweet\"][df_errors_transformer[\"predictions\"] == 1].str.split().explode().value_counts(normalize=True).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B-ftOl3aLt8"
      },
      "source": [
        "It can be deduced that the words occurrences for the two classes are different. In particular, the words distribution in the tweets classified as _non-sexist_ is quite uniform among all the tokens, as shown by the frequencies. On the other hand, for the _sexist_ samples, there is a predominance of some words, which is reflected also in the false positives predictions.\n",
        "\n",
        "As a consequence, the main deduction of this analysis is that **the Transformer model tends to classify a tweet as _sexist_ whenever it finds words related to genders like \"women\", \"men\" or like \"look\", even if they are used in a _non-sexist_ context**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwxYvTNGeOBY"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjsgIJBDeQVZ"
      },
      "outputs": [],
      "source": [
        "df_err_LSTM[df_err_LSTM[\"predictions\"] == 1][\"tweet\"].str.split().explode().value_counts(normalize=True).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elVg_v9pecZy"
      },
      "outputs": [],
      "source": [
        "df_err_LSTM[df_err_LSTM[\"predictions\"] == 0][\"tweet\"].str.split().explode().value_counts(normalize=True).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7ieR3J9egp4"
      },
      "outputs": [],
      "source": [
        "df_errors_LSTM[df_errors_LSTM[\"predictions\"] == 1][\"tweet\"].str.split().explode().value_counts(normalize=True).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKSYUqGsfOn9"
      },
      "source": [
        "The same deduction for the Trasformer holds also for the LSTM, with the differnce that in this case **the words under analysis are mostly \"woman\", \"like\" and \"men\"**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPNwYYtOCRyB"
      },
      "source": [
        "## Confusion Matrices\n",
        "Looking at the ***Confusion Matrices***, we can evaluate the performances of our binary classification models to discriminate positive from negative tweets.\n",
        "What can be inferred by the data below is:\n",
        "\n",
        "* **True Positives**\n",
        "  * The LSTM seems to have some troubles in classifying correctly positive tweets. Only the 64% of _sexist_ tweets is identified, with respect to the 83% of the Transformer model.\n",
        "* **False Positives**\n",
        "  * As a consequence, the false postives ratio of the LSTM is much higher than the one found for Transformer model, with 36% over 17%. If we suppose that a human supervisor is integrated in the overall system, this kind of misclassification might not be a so big issue.\n",
        "* **True Negatives**\n",
        "  * Considering the true negatives, the performance of the models are very similar (84% for the LSTM, 80% for the Transformer). Since identifying a _sexist_ text is more important than misclassifying a _non-sexist_ tweet and given the class imbalance shown before, these values are not quite encouraging for the LSTM.\n",
        "* **False Negatives**\n",
        "  * As already said, the 16% of false negatives for the LSTM and the 20% for the Transformer are quite good performances. However, not identifying a sexist tweet could be a serious problem, showing the need of some ways to manage the issue and reduce this percentage.\n",
        "  \n",
        "In general, the Transformer model seems to be more robust to the class imbalance and the implied biases, as the **False Negative** and **False Positive** percentages are more similar one another. On the other hand, given also the analysis of the word frequencies, the LSTM appears to be more affected by that bias. Further considerations can be done by looking a the **_Precision-Recall Curve_**.\n",
        "\n",
        "By considering the difference between **False Negative** and **False Positive** and having previously seen the class imbalance in training set, we could infer that this might lead our model to be more inclined to assign a 0 label to a tweet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzmW_u0RjiNu"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(df_err_LSTM['hard_labels_task1'].to_list(), df_err_LSTM['predictions'].to_list(), labels=[0,1], normalize=\"true\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T17:30:35.546792Z",
          "iopub.status.busy": "2024-11-27T17:30:35.545949Z",
          "iopub.status.idle": "2024-11-27T17:30:35.806039Z",
          "shell.execute_reply": "2024-11-27T17:30:35.805215Z",
          "shell.execute_reply.started": "2024-11-27T17:30:35.546760Z"
        },
        "id": "wlJfKEYH8DKZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(df_err_transformer['hard_labels_task1'].to_list(), df_err_transformer['predictions'].to_list(), labels=[0,1], normalize=\"true\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUybPh1OI9Vc"
      },
      "source": [
        "## Precision-Recall Curves\n",
        "\n",
        "In order to better understand the performances, strength and witnesses of each model, it is important to analyse the **_Precision-Recall Curves_** of the two models. They provide valuable insights into how the Transformer and LSTM models perform across varying thresholds, especially when balancing **precision** _(accuracy of positive predictions)_ and **recall** _(coverage of true positives)_.\n",
        "\n",
        "Unlike ***accuracy*** or ***ROC Curves***, the ***Precision-Recall Curves*** avoid overemphasizing true negatives, making them more reliable in scenarios where the positive class is costly to misclassify. Since in our task, misclassifying a _sexist_ tweet as _non-sexist_ one, might be a problem, using this curve is more reasonable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-27T17:33:54.379576Z",
          "iopub.status.busy": "2024-11-27T17:33:54.378858Z",
          "iopub.status.idle": "2024-11-27T17:33:54.734208Z",
          "shell.execute_reply": "2024-11-27T17:33:54.733350Z",
          "shell.execute_reply.started": "2024-11-27T17:33:54.379542Z"
        },
        "id": "EdkH7RrN7bEJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "PrecisionRecallDisplay.from_predictions(df_err_transformer['hard_labels_task1'], df_err_transformer['predictions'], name=\"Transformer\", ax=ax)\n",
        "PrecisionRecallDisplay.from_predictions(df_err_LSTM['hard_labels_task1'], df_err_LSTM['predictions'], name=\"LSTM\", ax=ax, plot_chance_level=True)\n",
        "ax.set_title(\"Precision-Recall Curve\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QRhx-ym4gk0"
      },
      "source": [
        "### Transformer\n",
        "The **Transformer** model demonstrates **strong performances with an average precision (AP) of 0.71**, which is higher than the LSTM, as expected. In general, the curve shows that:\n",
        "- at **_higher thresholds_**, so at _low recall values (left side)_, the Transformer achieves high precision, starting around **0.8**, and maintains this level up to a recall of approximately **0.8**. It means that, for much of the recall range, the Transformer is able to make accurate predictions.\n",
        "- at **_lower thresholds_**, as recall increases beyond 0.8 _(right side)_, there is a _steady drop in precision_. It means that where the model predicts more positives to increase recall, it also starts to misclassify more negative samples, introducing false positives.\n",
        "\n",
        "However, **the Transformer's overall ability to maintain high precision at moderate recall levels makes it a strong choice**. In addition, it maintains better precision across thresholds compared to the LSTM, confirming its superior balance between precision and recall.\n",
        "\n",
        "### LSTM\n",
        "The **LSTM** model, having an **average precision (AP) of 0.65**, shows resonably good performances, with a very similar behaviour with respect to the Transformer. In this case, it can be said that:\n",
        "- at **_higher tresholds_**, its _precision starts at the same value of the Transformer_, at around **0.8**, and remains relatively stable up to a recall of **0.6**. However, it is clear that the LSTM consistently **struggles to match the precision-recall balance achieved by the Transformer across all the recall levels**.\n",
        "- at **_lower tresholds_**, after a recall value of around **0.6**, the behaviour of the LSTM model is the same as the Transformer, reaching the precision levels of a chance predictor.\n",
        "\n",
        "In general, even if the the LSTM still performs well in certain regions, **its lower recall at lower tresholds suggests that it may be more prone to false negatives compared to the Transformer, as confirmed also by the confusion matrix**. This gap highlights areas where the LSTM could be further optimized, for example, by an appropriate threshold tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWW0YFaImuNA"
      },
      "source": [
        "## Conclusions and Possible Solutions\n",
        "What can be evinced from the entire analysis just presented is that the many things are in a way correlated. The _Precision-Recall Curves_ and the _Confusion Matrices_ are referred to the same kind of analysis, as said before. Also the type of information provided is influenced by the _class imbalance_, which is one of the main causes for poor performances in terms of shape of the PR Curve and the AP, especially for the LSTM model.\n",
        "\n",
        "To address these issues, there could be different solutions, some for the data manipulation and some for model improvements. Regarding data:\n",
        "\n",
        "- **rebalancing the training process by applying _class weights_** during the computation of the loss, such to help the model giving equal importance to both classes.\n",
        "\n",
        "- **data augmentation**, since the dataset size is pretty small, and can be done by gathering new data from other sources or reshuffling the tokenized tweets in actual data, as a pre-processing operation.\n",
        "\n",
        "- changing the **batch creation strategy** by mixing inputs, such to have always a similar number of data for each lenght range. It can be done by keeping the mean of the tweet lenghts equal or at least similar for all the batches in ach epoch.\n",
        "\n",
        "Regarding the models:\n",
        "\n",
        "- a way of improving the LSTM is to **increase the number of bidirectional blocks** and add **skip connections** to avoid the vanishing gradient problem.\n",
        "- for the Transformer, a possibility to get better performances is to **change the fine-tuning strategy, like freezing part of the network and updating the remaining weights**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P42XYjb6K3k5"
      },
      "source": [
        "# [Task 8 - 0.5 points] Report\n",
        "\n",
        "\n",
        "\n",
        "Wrap up your experiment in a short report (up to 2 pages)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9oXSaW1K5S7"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "\n",
        "\n",
        "* Use the NLP course report template.\n",
        "\n",
        "* Summarize each task in the report following the provided template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHw2L6PlLDyE"
      },
      "source": [
        "### Recommendations\n",
        "\n",
        "\n",
        "\n",
        "The report is not a copy-paste of graphs, tables, and command outputs.\n",
        "\n",
        "\n",
        "\n",
        "* Summarize classification performance in Table format.\n",
        "\n",
        "* **Do not** report command outputs or screenshots.\n",
        "\n",
        "* Report learning curves in Figure format.\n",
        "\n",
        "* The error analysis section should summarize your findings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMUqh1utLflM"
      },
      "source": [
        "# Submission\n",
        "\n",
        "\n",
        "\n",
        "* **Submit** your report in PDF format.\n",
        "\n",
        "* **Submit** your python notebook.\n",
        "\n",
        "* Make sure your notebook is **well organized**, with no temporary code, commented sections, tests, etc...\n",
        "\n",
        "* You can upload **model weights** in a cloud repository and report the link in the report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypagJed7LheY"
      },
      "source": [
        "# FAQ\n",
        "\n",
        "\n",
        "\n",
        "Please check this frequently asked questions before contacting us"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgtFwKXMLjww"
      },
      "source": [
        "### Execution Order\n",
        "\n",
        "\n",
        "\n",
        "You are **free** to address tasks in any order (if multiple orderings are available)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BjMk5e_M4n7"
      },
      "source": [
        "### Trainable Embeddings\n",
        "\n",
        "\n",
        "\n",
        "You are **free** to define a trainable or non-trainable Embedding layer to load the GloVe embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8TVgpYlM6s5"
      },
      "source": [
        "### Model architecture\n",
        "\n",
        "\n",
        "\n",
        "You **should not** change the architecture of a model (i.e., its layers).\n",
        "\n",
        "However, you are **free** to play with their hyper-parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia6IapI1M_A7"
      },
      "source": [
        "### Neural Libraries\n",
        "\n",
        "\n",
        "\n",
        "You are **free** to use any library of your choice to implement the networks (e.g., Keras, Tensorflow, PyTorch, JAX, etc...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWDaW8DyNBu5"
      },
      "source": [
        "### Keras TimeDistributed Dense layer\n",
        "\n",
        "\n",
        "\n",
        "If you are using Keras, we recommend wrapping the final Dense layer with `TimeDistributed`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1WcrpemNEQm"
      },
      "source": [
        "### Robust Evaluation\n",
        "\n",
        "\n",
        "\n",
        "Each model is trained with at least 3 random seeds.\n",
        "\n",
        "\n",
        "\n",
        "Task 4 requires you to compute the average performance over the 3 seeds and its corresponding standard deviation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mVe5dqzNI_u"
      },
      "source": [
        "### Model Selection for Analysis\n",
        "\n",
        "\n",
        "\n",
        "To carry out the error analysis you are **free** to either\n",
        "\n",
        "\n",
        "\n",
        "* Pick examples or perform comparisons with an individual seed run model (e.g., Baseline seed 1337)\n",
        "\n",
        "* Perform ensembling via, for instance, majority voting to obtain a single model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8a4pDKSNKzI"
      },
      "source": [
        "### Error Analysis\n",
        "\n",
        "\n",
        "\n",
        "Some topics for discussion include:\n",
        "\n",
        "   * Precision/Recall curves.\n",
        "\n",
        "   * Confusion matrices.\n",
        "\n",
        "   * Specific misclassified samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "2LnpfYNWIMET",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "### Bonus Points\n",
        "\n",
        "Bonus points are arbitrarily assigned based on significant contributions such as:\n",
        "\n",
        "- Outstanding error analysis\n",
        "\n",
        "- Masterclass code organization\n",
        "\n",
        "- Suitable extensions\n",
        "\n",
        "Note that bonus points are only assigned if all task points are attributed (i.e., 6/6).\n",
        "\n",
        "\n",
        "\n",
        "**Possible Extensions/Explorations for Bonus Points:**\n",
        "\n",
        "- **Try other preprocessing strategies**: e.g., but not limited to, explore techniques tailored specifically for tweets or  methods that are common in social media text.\n",
        "\n",
        "- **Experiment with other custom architectures or models from HuggingFace**\n",
        "\n",
        "- **Explore Spanish tweets**: e.g., but not limited to, leverage multilingual models to process Spanish tweets and assess their performance compared to monolingual models.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xmMKE7vLu-y"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# The End"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30787,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f1eb5d9b27e94ce6a086f87f6b2ed2a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78c34feee79a46debe1cb9b04a3864e9",
              "IPY_MODEL_8087c307a15f4ebabbb415058ae08cdc",
              "IPY_MODEL_9f5aacc2dd8f412eae8b2a7716972bb0"
            ],
            "layout": "IPY_MODEL_281b84aa936a4381925edc4fadcf36ef"
          }
        },
        "78c34feee79a46debe1cb9b04a3864e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fd07001d9e144cab6c7f81edf8194f3",
            "placeholder": "​",
            "style": "IPY_MODEL_cedf030ac38a4460aae7ca6c4590daec",
            "value": "Map: 100%"
          }
        },
        "8087c307a15f4ebabbb415058ae08cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56e42697437e4a4ab34df9cfa69fe339",
            "max": 2870,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a71c9431040a48938fc890f2ae22a322",
            "value": 2870
          }
        },
        "9f5aacc2dd8f412eae8b2a7716972bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0913e0fafc1c48eeb150143745869a7f",
            "placeholder": "​",
            "style": "IPY_MODEL_0538b2f513a14baca091a6a17631b08d",
            "value": " 2870/2870 [00:00&lt;00:00, 4222.35 examples/s]"
          }
        },
        "281b84aa936a4381925edc4fadcf36ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fd07001d9e144cab6c7f81edf8194f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cedf030ac38a4460aae7ca6c4590daec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56e42697437e4a4ab34df9cfa69fe339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a71c9431040a48938fc890f2ae22a322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0913e0fafc1c48eeb150143745869a7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0538b2f513a14baca091a6a17631b08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "470e9585e925493e92e7d2e64d969a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffdfd24abe7f49dda035bc86efd7b71b",
              "IPY_MODEL_3342b67848ed475f9115a3b7e4b97ad3",
              "IPY_MODEL_a9613759bdc1435ea43526d9df3a3a60"
            ],
            "layout": "IPY_MODEL_a9517504813a4230a1c27c00ff717b8c"
          }
        },
        "ffdfd24abe7f49dda035bc86efd7b71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08247ab3f1954f9298df9f97f0d452a6",
            "placeholder": "​",
            "style": "IPY_MODEL_f83249d876af47c9bb4b39ed0485edd9",
            "value": "Map: 100%"
          }
        },
        "3342b67848ed475f9115a3b7e4b97ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baa0e90900c34302b03a8a23dc2aa5f2",
            "max": 158,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58df9f10b6f0466f89841384a8e74950",
            "value": 158
          }
        },
        "a9613759bdc1435ea43526d9df3a3a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dec5d8b223d4062b223011264230e6a",
            "placeholder": "​",
            "style": "IPY_MODEL_36137c437cbc4ce48c6e128d0cb11231",
            "value": " 158/158 [00:00&lt;00:00, 3609.38 examples/s]"
          }
        },
        "a9517504813a4230a1c27c00ff717b8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08247ab3f1954f9298df9f97f0d452a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f83249d876af47c9bb4b39ed0485edd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baa0e90900c34302b03a8a23dc2aa5f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58df9f10b6f0466f89841384a8e74950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4dec5d8b223d4062b223011264230e6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36137c437cbc4ce48c6e128d0cb11231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f8d6fbe2467427a8f71279c8145961d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10d2f7ab833e42639fa5c3cc7b31872c",
              "IPY_MODEL_34d2238a8c994a2ab465f97cb0081f96",
              "IPY_MODEL_77eaab8a1b074355842b9c3d357ff937"
            ],
            "layout": "IPY_MODEL_004edb525df3421ababeddeb6d445b08"
          }
        },
        "10d2f7ab833e42639fa5c3cc7b31872c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1215cca066c4d2888b68597fe9eb324",
            "placeholder": "​",
            "style": "IPY_MODEL_db8e4f36e7bd4893b70a52ebeae87050",
            "value": "Map: 100%"
          }
        },
        "34d2238a8c994a2ab465f97cb0081f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8514d15c821b43a6978b5d836905dee3",
            "max": 286,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b140766256b948bf9eeac9f35e7c5133",
            "value": 286
          }
        },
        "77eaab8a1b074355842b9c3d357ff937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edd304dd396341b987b61c13e1e0b8d6",
            "placeholder": "​",
            "style": "IPY_MODEL_ea222f925689483d9eab61462202a9dd",
            "value": " 286/286 [00:00&lt;00:00, 6216.62 examples/s]"
          }
        },
        "004edb525df3421ababeddeb6d445b08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1215cca066c4d2888b68597fe9eb324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db8e4f36e7bd4893b70a52ebeae87050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8514d15c821b43a6978b5d836905dee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b140766256b948bf9eeac9f35e7c5133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edd304dd396341b987b61c13e1e0b8d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea222f925689483d9eab61462202a9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15f91948c7bf48d4bb457e5b731054c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_faea7d13c37f432aa3013ad0f86f748b",
              "IPY_MODEL_e214504b66fa47c6b33d31fedda5e80c",
              "IPY_MODEL_b5567d5ff43d44418d945ff6e8acf5db"
            ],
            "layout": "IPY_MODEL_277c529fccf3418e84e7a9d7041f72b6"
          }
        },
        "faea7d13c37f432aa3013ad0f86f748b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd2b912fb34642da9ef7cefe237f9afb",
            "placeholder": "​",
            "style": "IPY_MODEL_e06aebebc2c641d4a116d141e7d0d2e2",
            "value": "Map: 100%"
          }
        },
        "e214504b66fa47c6b33d31fedda5e80c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2321710873946d7bd476263659630f4",
            "max": 3194,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9df702cd52524ea5a04b61804c1e2a2a",
            "value": 3194
          }
        },
        "b5567d5ff43d44418d945ff6e8acf5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2628db3dfbbe4b6ba52c6e542a8a0abe",
            "placeholder": "​",
            "style": "IPY_MODEL_53a51333c9014034860186133a882852",
            "value": " 3194/3194 [00:00&lt;00:00, 7041.56 examples/s]"
          }
        },
        "277c529fccf3418e84e7a9d7041f72b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd2b912fb34642da9ef7cefe237f9afb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e06aebebc2c641d4a116d141e7d0d2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2321710873946d7bd476263659630f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9df702cd52524ea5a04b61804c1e2a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2628db3dfbbe4b6ba52c6e542a8a0abe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53a51333c9014034860186133a882852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5211205c6ad24e549a0fbe0b999a0a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_357397d4e0df455f9b7e9037dbe8a695",
              "IPY_MODEL_84cc9749187543f2a44fe415edede768",
              "IPY_MODEL_a624967a95f6447d87ced0216e6b34a5"
            ],
            "layout": "IPY_MODEL_8456f7edc7ff4fbda56325bdb93eab56"
          }
        },
        "357397d4e0df455f9b7e9037dbe8a695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3d7dd35eb074b49abaaf68c75e783d6",
            "placeholder": "​",
            "style": "IPY_MODEL_509caec5f0c64b2eaabc404bc415d4f9",
            "value": "Map: 100%"
          }
        },
        "84cc9749187543f2a44fe415edede768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2af38a514812494984c53ca7c85332f6",
            "max": 490,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06343bda44174b5abe7c77e595ac91e6",
            "value": 490
          }
        },
        "a624967a95f6447d87ced0216e6b34a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c28d74713ebe44c4aa7e320e64aa4fc8",
            "placeholder": "​",
            "style": "IPY_MODEL_672881480bc543bda7b137d842cbdd90",
            "value": " 490/490 [00:00&lt;00:00, 5753.26 examples/s]"
          }
        },
        "8456f7edc7ff4fbda56325bdb93eab56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3d7dd35eb074b49abaaf68c75e783d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "509caec5f0c64b2eaabc404bc415d4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2af38a514812494984c53ca7c85332f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06343bda44174b5abe7c77e595ac91e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c28d74713ebe44c4aa7e320e64aa4fc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "672881480bc543bda7b137d842cbdd90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}